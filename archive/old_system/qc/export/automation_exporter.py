#!/usr/bin/env python3
"""
Automation Results Exporter

Export and publication tools for automated qualitative coding results,
including evidence tables, automation reports, pattern analysis, and
network diagram data compatible with external visualization tools.
"""

import asyncio
import json
import csv
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path
import io

from ..core.neo4j_manager import EnhancedNeo4jManager

logger = logging.getLogger(__name__)


class AutomationResultsExporter:
    """Export automated qualitative coding results in various formats"""
    
    def __init__(self, neo4j_manager: EnhancedNeo4jManager = None):
        self.neo4j = neo4j_manager
        self.supported_formats = ["markdown", "html", "csv", "json", "latex", "academic"]
    
    async def export_evidence_table(self, finding: str, format: str = "markdown") -> str:
        """
        Export finding with supporting quotes and line numbers
        
        Args:
            finding: Finding ID or name to export evidence for
            format: Output format (markdown, html, csv, json, latex, academic)
            
        Returns:
            Formatted evidence table string
        """
        if format not in self.supported_formats:
            raise ValueError(f"Unsupported format: {format}. Supported: {self.supported_formats}")
        
        # For this implementation, we'll assume finding is an entity ID
        # In a real implementation, we'd need to determine if it's entity or code
        try:
            provenance = await self.neo4j.get_provenance_chain(finding, "entity")
        except:
            # Try as code if entity fails
            provenance = await self.neo4j.get_provenance_chain(finding, "code")
        
        if "error" in provenance:
            return f"Error: {provenance['error']}"
        
        if format == "markdown":
            return self._export_evidence_markdown(provenance)
        elif format == "html":
            return self._export_evidence_html(provenance)
        elif format == "csv":
            return self._export_evidence_csv(provenance)
        elif format == "json":
            return self._export_evidence_json(provenance)
        elif format == "latex":
            return self._export_evidence_latex(provenance)
        elif format == "academic":
            return self._export_evidence_academic(provenance)
        else:
            raise ValueError(f"Format {format} not implemented")
    
    def _export_evidence_markdown(self, provenance: Dict[str, Any]) -> str:
        """Export evidence table in Markdown format"""
        finding = provenance["finding"]
        evidence_chain = provenance["evidence_chain"]
        
        lines = []
        lines.append(f"# Evidence Table: {finding['name']}")
        lines.append("")
        lines.append(f"**Finding Type:** {provenance['finding_type']}")
        lines.append(f"**Evidence Count:** {provenance['evidence_count']}")
        lines.append(f"**Generated:** {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}")
        lines.append("")
        
        if evidence_chain:
            lines.append("## Supporting Evidence")
            lines.append("")
            lines.append("| Quote ID | Interview | Lines | Confidence | Text | Context |")
            lines.append("|----------|-----------|-------|------------|------|---------|")
            
            for evidence in evidence_chain:
                confidence_str = f"{evidence['confidence']:.2f}" if evidence['confidence'] else "N/A"
                text_preview = evidence['text'][:100] + "..." if len(evidence['text']) > 100 else evidence['text']
                context_preview = evidence.get('context', '')[:50] + "..." if evidence.get('context') and len(evidence.get('context', '')) > 50 else evidence.get('context', '')
                
                lines.append(f"| {evidence['quote_id']} | {evidence['interview_id']} | {evidence['line_range']} | {confidence_str} | \"{text_preview}\" | {context_preview} |")
        else:
            lines.append("*No supporting evidence found.*")
        
        lines.append("")
        lines.append("---")
        lines.append("*Generated by Automated Qualitative Coding System*")
        
        return "\n".join(lines)
    
    def _export_evidence_html(self, provenance: Dict[str, Any]) -> str:
        """Export evidence table in HTML format"""
        finding = provenance["finding"]
        evidence_chain = provenance["evidence_chain"]
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Evidence Table: {finding['name']}</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 2rem; }}
                table {{ border-collapse: collapse; width: 100%; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
                .confidence-high {{ color: green; font-weight: bold; }}
                .confidence-medium {{ color: orange; font-weight: bold; }}
                .confidence-low {{ color: red; font-weight: bold; }}
                .quote-text {{ font-style: italic; }}
            </style>
        </head>
        <body>
            <h1>Evidence Table: {finding['name']}</h1>
            <p><strong>Finding Type:</strong> {provenance['finding_type']}</p>
            <p><strong>Evidence Count:</strong> {provenance['evidence_count']}</p>
            <p><strong>Generated:</strong> {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}</p>
            
            <h2>Supporting Evidence</h2>
        """
        
        if evidence_chain:
            html += """
            <table>
                <thead>
                    <tr>
                        <th>Quote ID</th>
                        <th>Interview</th>
                        <th>Lines</th>
                        <th>Confidence</th>
                        <th>Text</th>
                        <th>Context</th>
                    </tr>
                </thead>
                <tbody>
            """
            
            for evidence in evidence_chain:
                confidence = evidence.get('confidence', 0)
                confidence_class = "confidence-high" if confidence >= 0.8 else "confidence-medium" if confidence >= 0.6 else "confidence-low"
                confidence_str = f"{confidence:.2f}" if confidence else "N/A"
                
                text_preview = evidence['text'][:150] + "..." if len(evidence['text']) > 150 else evidence['text']
                context_preview = evidence.get('context', '')[:100] + "..." if evidence.get('context') and len(evidence.get('context', '')) > 100 else evidence.get('context', '')
                
                html += f"""
                    <tr>
                        <td>{evidence['quote_id']}</td>
                        <td>{evidence['interview_id']}</td>
                        <td>{evidence['line_range']}</td>
                        <td class="{confidence_class}">{confidence_str}</td>
                        <td class="quote-text">"{text_preview}"</td>
                        <td>{context_preview}</td>
                    </tr>
                """
            
            html += """
                </tbody>
            </table>
            """
        else:
            html += "<p><em>No supporting evidence found.</em></p>"
        
        html += """
            <hr>
            <p><em>Generated by Automated Qualitative Coding System</em></p>
        </body>
        </html>
        """
        
        return html
    
    def _export_evidence_csv(self, provenance: Dict[str, Any]) -> str:
        """Export evidence table in CSV format"""
        output = io.StringIO()
        writer = csv.writer(output)
        
        # Header
        writer.writerow(["Quote_ID", "Interview_ID", "Line_Range", "Confidence", "Text", "Context", "Finding_Name", "Finding_Type"])
        
        # Data rows
        finding_name = provenance["finding"]["name"]
        finding_type = provenance["finding_type"]
        
        for evidence in provenance["evidence_chain"]:
            writer.writerow([
                evidence["quote_id"],
                evidence["interview_id"],
                evidence["line_range"],
                evidence.get("confidence", ""),
                evidence["text"],
                evidence.get("context", ""),
                finding_name,
                finding_type
            ])
        
        return output.getvalue()
    
    def _export_evidence_json(self, provenance: Dict[str, Any]) -> str:
        """Export evidence table in JSON format"""
        export_data = {
            "finding": provenance["finding"],
            "finding_type": provenance["finding_type"],
            "evidence_count": provenance["evidence_count"],
            "evidence_chain": provenance["evidence_chain"],
            "generated_at": datetime.utcnow().isoformat(),
            "generator": "Automated Qualitative Coding System"
        }
        
        return json.dumps(export_data, indent=2, ensure_ascii=False)
    
    def _export_evidence_latex(self, provenance: Dict[str, Any]) -> str:
        """Export evidence table in LaTeX format"""
        finding = provenance["finding"]
        evidence_chain = provenance["evidence_chain"]
        
        latex = f"""
\\documentclass{{article}}
\\usepackage[utf8]{{inputenc}}
\\usepackage{{booktabs}}
\\usepackage{{longtable}}
\\usepackage{{array}}
\\usepackage{{xcolor}}

\\title{{Evidence Table: {finding['name']}}}
\\author{{Automated Qualitative Coding System}}
\\date{{{datetime.utcnow().strftime('%Y-%m-%d')}}}

\\begin{{document}}

\\maketitle

\\section{{Finding Details}}
\\begin{{itemize}}
    \\item \\textbf{{Finding Type:}} {provenance['finding_type']}
    \\item \\textbf{{Evidence Count:}} {provenance['evidence_count']}
    \\item \\textbf{{Generated:}} {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}
\\end{{itemize}}

\\section{{Supporting Evidence}}

\\begin{{longtable}}{{|p{{2cm}}|p{{2cm}}|p{{1.5cm}}|p{{1.5cm}}|p{{5cm}}|p{{3cm}}|}}
\\hline
\\textbf{{Quote ID}} & \\textbf{{Interview}} & \\textbf{{Lines}} & \\textbf{{Confidence}} & \\textbf{{Text}} & \\textbf{{Context}} \\\\
\\hline
\\endhead
"""
        
        for evidence in evidence_chain:
            confidence_str = f"{evidence['confidence']:.2f}" if evidence['confidence'] else "N/A"
            
            # Escape LaTeX special characters
            text = evidence['text'].replace('&', '\\&').replace('%', '\\%').replace('$', '\\$').replace('#', '\\#').replace('_', '\\_').replace('{', '\\{').replace('}', '\\}')
            context = evidence.get('context', '').replace('&', '\\&').replace('%', '\\%').replace('$', '\\$').replace('#', '\\#').replace('_', '\\_').replace('{', '\\{').replace('}', '\\}')
            
            # Truncate for LaTeX table
            text_preview = text[:100] + "..." if len(text) > 100 else text
            context_preview = context[:50] + "..." if len(context) > 50 else context
            
            latex += f"{evidence['quote_id']} & {evidence['interview_id']} & {evidence['line_range']} & {confidence_str} & \"{text_preview}\" & {context_preview} \\\\ \\hline\n"
        
        latex += """
\\end{longtable}

\\end{document}
"""
        
        return latex
    
    def _export_evidence_academic(self, provenance: Dict[str, Any]) -> str:
        """Export evidence table in academic publication format"""
        finding = provenance["finding"]
        evidence_chain = provenance["evidence_chain"]
        
        lines = []
        lines.append(f"**Table X.** Evidence supporting the identification of '{finding['name']}' in qualitative data analysis")
        lines.append("")
        
        # Academic-style table
        lines.append("| Source | Location | Confidence | Evidence |")
        lines.append("|--------|----------|------------|----------|")
        
        for i, evidence in enumerate(evidence_chain, 1):
            confidence_str = f"{evidence['confidence']:.2f}" if evidence['confidence'] else "N/A"
            text_citation = f"\"{evidence['text'][:200]}{'...' if len(evidence['text']) > 200 else ''}\""
            location = f"{evidence['interview_id']}:{evidence['line_range']}"
            
            lines.append(f"| P{i:02d} | {location} | {confidence_str} | {text_citation} |")
        
        lines.append("")
        lines.append(f"*Note.* Table shows {len(evidence_chain)} instances of automated detection ")
        lines.append(f"for the {provenance['finding_type']} '{finding['name']}'. Confidence scores ")
        lines.append("represent automated classification certainty (0.0-1.0). Location format: ")
        lines.append("Interview_ID:Line_Range. Generated by automated qualitative coding system.")
        
        return "\n".join(lines)
    
    async def export_automation_report(self, interview_ids: List[str] = None, format: str = "markdown") -> str:
        """
        Export complete automation summary with statistics
        
        Args:
            interview_ids: Optional list of interview IDs to include
            format: Output format
            
        Returns:
            Formatted automation report
        """
        summary = await self.neo4j.get_automation_summary(interview_ids)
        
        if format == "markdown":
            return self._export_report_markdown(summary)
        elif format == "html":
            return self._export_report_html(summary)
        elif format == "json":
            return json.dumps(summary, indent=2, ensure_ascii=False)
        elif format == "academic":
            return self._export_report_academic(summary)
        else:
            raise ValueError(f"Format {format} not implemented for automation report")
    
    def _export_report_markdown(self, summary: Dict[str, Any]) -> str:
        """Export automation report in Markdown format"""
        stats = summary["statistics"]
        conf_dist = summary.get("confidence_distribution", {})
        timeline = summary.get("timeline", {})
        
        lines = []
        lines.append("# Automated Qualitative Coding Report")
        lines.append("")
        lines.append(f"**Generated:** {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}")
        lines.append(f"**System:** Automated Qualitative Coding Analysis Tool")
        lines.append("")
        
        # Overall statistics
        lines.append("## Overall Statistics")
        lines.append("")
        lines.append(f"- **Interviews Processed:** {stats.get('interviews_processed', 0)}")
        lines.append(f"- **Quotes Extracted:** {stats.get('quotes_extracted', 0)}")
        lines.append(f"- **Quote Nodes Created:** {stats.get('quote_nodes', 0)}")
        lines.append(f"- **Entities Detected:** {stats.get('entities_detected', 0)}")
        lines.append(f"- **Entity Relationships:** {stats.get('entity_relationships', 0)}")
        lines.append(f"- **Code Assignments:** {stats.get('code_assignments', 0)}")
        lines.append("")
        
        # Confidence distribution
        if conf_dist:
            lines.append("## Confidence Distribution")
            lines.append("")
            total = conf_dist.get('high', 0) + conf_dist.get('medium', 0) + conf_dist.get('low', 0)
            if total > 0:
                high_pct = (conf_dist.get('high', 0) / total * 100)
                med_pct = (conf_dist.get('medium', 0) / total * 100)
                low_pct = (conf_dist.get('low', 0) / total * 100)
                
                lines.append(f"- **High Confidence (≥0.8):** {conf_dist.get('high', 0)} items ({high_pct:.1f}%)")
                lines.append(f"- **Medium Confidence (0.6-0.8):** {conf_dist.get('medium', 0)} items ({med_pct:.1f}%)")
                lines.append(f"- **Low Confidence (<0.6):** {conf_dist.get('low', 0)} items ({low_pct:.1f}%)")
                lines.append("")
        
        # Processing timeline
        if timeline:
            lines.append("## Processing Timeline")
            lines.append("")
            lines.append("| Interview ID | Quotes | Entities |")
            lines.append("|--------------|--------|----------|")
            
            for interview_id, info in timeline.items():
                lines.append(f"| {interview_id} | {info.get('quotes', 0)} | {info.get('entities', 0)} |")
            lines.append("")
        
        lines.append("---")
        lines.append("*This report was generated automatically by the Qualitative Coding Analysis Tool*")
        
        return "\n".join(lines)
    
    def _export_report_html(self, summary: Dict[str, Any]) -> str:
        """Export automation report in HTML format"""
        stats = summary["statistics"]
        conf_dist = summary.get("confidence_distribution", {})
        timeline = summary.get("timeline", {})
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Automated Qualitative Coding Report</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 2rem; line-height: 1.6; }}
                table {{ border-collapse: collapse; width: 100%; margin: 1rem 0; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
                .stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 1rem; margin: 1rem 0; }}
                .stat-card {{ background: #f8f9fa; padding: 1rem; border-radius: 5px; text-align: center; }}
                .stat-value {{ font-size: 2rem; font-weight: bold; color: #007bff; }}
                .stat-label {{ color: #6c757d; }}
            </style>
        </head>
        <body>
            <h1>Automated Qualitative Coding Report</h1>
            <p><strong>Generated:</strong> {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}</p>
            <p><strong>System:</strong> Automated Qualitative Coding Analysis Tool</p>
            
            <h2>Overall Statistics</h2>
            <div class="stats">
                <div class="stat-card">
                    <div class="stat-value">{stats.get('interviews_processed', 0)}</div>
                    <div class="stat-label">Interviews Processed</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{stats.get('quotes_extracted', 0)}</div>
                    <div class="stat-label">Quotes Extracted</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{stats.get('entities_detected', 0)}</div>
                    <div class="stat-label">Entities Detected</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{stats.get('code_assignments', 0)}</div>
                    <div class="stat-label">Code Assignments</div>
                </div>
            </div>
        """
        
        # Confidence distribution
        if conf_dist:
            total = conf_dist.get('high', 0) + conf_dist.get('medium', 0) + conf_dist.get('low', 0)
            if total > 0:
                high_pct = (conf_dist.get('high', 0) / total * 100)
                med_pct = (conf_dist.get('medium', 0) / total * 100)
                low_pct = (conf_dist.get('low', 0) / total * 100)
                
                html += f"""
                <h2>Confidence Distribution</h2>
                <ul>
                    <li><strong>High Confidence (≥0.8):</strong> {conf_dist.get('high', 0)} items ({high_pct:.1f}%)</li>
                    <li><strong>Medium Confidence (0.6-0.8):</strong> {conf_dist.get('medium', 0)} items ({med_pct:.1f}%)</li>
                    <li><strong>Low Confidence (&lt;0.6):</strong> {conf_dist.get('low', 0)} items ({low_pct:.1f}%)</li>
                </ul>
                """
        
        # Processing timeline
        if timeline:
            html += """
            <h2>Processing Timeline</h2>
            <table>
                <thead>
                    <tr>
                        <th>Interview ID</th>
                        <th>Quotes</th>
                        <th>Entities</th>
                    </tr>
                </thead>
                <tbody>
            """
            
            for interview_id, info in timeline.items():
                html += f"""
                    <tr>
                        <td>{interview_id}</td>
                        <td>{info.get('quotes', 0)}</td>
                        <td>{info.get('entities', 0)}</td>
                    </tr>
                """
            
            html += """
                </tbody>
            </table>
            """
        
        html += """
            <hr>
            <p><em>This report was generated automatically by the Qualitative Coding Analysis Tool</em></p>
        </body>
        </html>
        """
        
        return html
    
    def _export_report_academic(self, summary: Dict[str, Any]) -> str:
        """Export automation report in academic format"""
        stats = summary["statistics"]
        conf_dist = summary.get("confidence_distribution", {})
        
        lines = []
        lines.append("**Automated Analysis Results Summary**")
        lines.append("")
        
        lines.append(f"The automated qualitative coding system processed {stats.get('interviews_processed', 0)} ")
        lines.append(f"interviews, extracting {stats.get('quotes_extracted', 0)} semantic quotes and ")
        lines.append(f"identifying {stats.get('entities_detected', 0)} distinct entities with ")
        lines.append(f"{stats.get('entity_relationships', 0)} documented relationships. ")
        
        if conf_dist:
            total = conf_dist.get('high', 0) + conf_dist.get('medium', 0) + conf_dist.get('low', 0)
            if total > 0:
                high_pct = (conf_dist.get('high', 0) / total * 100)
                lines.append(f"Of the automated classifications, {high_pct:.1f}% achieved high confidence ")
                lines.append("scores (≥0.8), indicating strong algorithmic certainty in the assigned codes.")
        
        lines.append("")
        lines.append("The automated system demonstrated systematic coverage across the dataset, ")
        lines.append("with consistent entity detection and relationship mapping. All results ")
        lines.append("include confidence scores and full provenance chains linking findings ")
        lines.append("to specific textual evidence with precise line-number citations.")
        
        return "\n".join(lines)
    
    async def export_pattern_analysis(self, patterns: List[Dict] = None, format: str = "academic") -> str:
        """
        Export automatically detected patterns for publication
        
        Args:
            patterns: List of pattern dictionaries, if None will fetch from database
            format: Output format
            
        Returns:
            Formatted pattern analysis
        """
        if patterns is None:
            patterns = await self.neo4j.get_automated_patterns(min_confidence=0.7)
        
        if format == "academic":
            return self._export_patterns_academic(patterns)
        elif format == "markdown":
            return self._export_patterns_markdown(patterns)
        elif format == "json":
            return json.dumps(patterns, indent=2, ensure_ascii=False)
        else:
            raise ValueError(f"Format {format} not implemented for pattern analysis")
    
    def _export_patterns_academic(self, patterns: List[Dict]) -> str:
        """Export patterns in academic format"""
        lines = []
        lines.append("**Automated Pattern Detection Results**")
        lines.append("")
        
        entity_patterns = [p for p in patterns if p.get('pattern_type') == 'entity_pattern']
        code_patterns = [p for p in patterns if p.get('pattern_type') == 'code_pattern']
        
        lines.append(f"Automated analysis identified {len(patterns)} significant patterns ")
        lines.append(f"across the dataset, including {len(entity_patterns)} entity-based patterns ")
        lines.append(f"and {len(code_patterns)} thematic code patterns. ")
        
        if patterns:
            avg_confidence = sum(p.get('confidence', 0) for p in patterns) / len(patterns)
            cross_interview = sum(1 for p in patterns if p.get('cross_interview', False))
            
            lines.append(f"Pattern detection achieved an average confidence of {avg_confidence:.2f}, ")
            lines.append(f"with {cross_interview} patterns ({cross_interview/len(patterns)*100:.1f}%) ")
            lines.append("appearing across multiple interviews, indicating thematic consistency.")
            lines.append("")
            
            # Top patterns
            top_patterns = sorted(patterns, key=lambda x: x.get('frequency', 0), reverse=True)[:5]
            lines.append("**Most Frequent Patterns:**")
            lines.append("")
            
            for i, pattern in enumerate(top_patterns, 1):
                lines.append(f"{i}. **{pattern['name']}** ({pattern.get('pattern_type', 'unknown')}): ")
                lines.append(f"   Frequency: {pattern.get('frequency', 0)}, ")
                lines.append(f"   Confidence: {pattern.get('confidence', 0):.2f}, ")
                lines.append(f"   Cross-interview: {'Yes' if pattern.get('cross_interview') else 'No'}")
                lines.append("")
        
        return "\n".join(lines)
    
    def _export_patterns_markdown(self, patterns: List[Dict]) -> str:
        """Export patterns in Markdown format"""
        lines = []
        lines.append("# Automated Pattern Analysis")
        lines.append("")
        lines.append(f"**Generated:** {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}")
        lines.append(f"**Total Patterns:** {len(patterns)}")
        lines.append("")
        
        if patterns:
            # Summary statistics
            entity_patterns = len([p for p in patterns if p.get('pattern_type') == 'entity_pattern'])
            code_patterns = len([p for p in patterns if p.get('pattern_type') == 'code_pattern'])
            cross_interview = len([p for p in patterns if p.get('cross_interview', False)])
            
            lines.append("## Summary")
            lines.append("")
            lines.append(f"- **Entity Patterns:** {entity_patterns}")
            lines.append(f"- **Code Patterns:** {code_patterns}")
            lines.append(f"- **Cross-Interview Patterns:** {cross_interview}")
            lines.append("")
            
            # Pattern details
            lines.append("## Pattern Details")
            lines.append("")
            lines.append("| Pattern | Type | Frequency | Confidence | Cross-Interview | Description |")
            lines.append("|---------|------|-----------|------------|-----------------|-------------|")
            
            for pattern in sorted(patterns, key=lambda x: x.get('confidence', 0), reverse=True):
                cross_interview_marker = "✓" if pattern.get('cross_interview') else "✗"
                lines.append(f"| {pattern['name']} | {pattern.get('pattern_type', 'unknown')} | {pattern.get('frequency', 0)} | {pattern.get('confidence', 0):.2f} | {cross_interview_marker} | {pattern.get('description', '')} |")
        
        lines.append("")
        lines.append("---")
        lines.append("*Generated by Automated Qualitative Coding System*")
        
        return "\n".join(lines)
    
    async def export_network_diagram_data(self, interview_ids: List[str] = None) -> Dict[str, Any]:
        """
        Export relationship data for external visualization tools
        
        Args:
            interview_ids: Optional list of interview IDs to include
            
        Returns:
            Network data compatible with Cytoscape, Gephi, etc.
        """
        # Get automation summary to understand the data
        summary = await self.neo4j.get_automation_summary(interview_ids)
        
        # Get all quotes with assignments
        all_quotes = []
        for interview_id in summary.get("interview_ids", []):
            quotes = await self.neo4j.get_quotes_with_assignments(interview_id, include_confidence=True)
            all_quotes.extend(quotes)
        
        # Build network data
        nodes = []
        edges = []
        node_ids = set()
        
        # Add quote nodes
        for quote in all_quotes:
            if quote['id'] not in node_ids:
                nodes.append({
                    "id": quote['id'],
                    "label": f"Quote {quote['id']}",
                    "type": "quote",
                    "interview_id": quote['interview_id'],
                    "text": quote['text'][:100] + "..." if len(quote['text']) > 100 else quote['text'],
                    "confidence": quote.get('confidence', 0),
                    "line_range": f"{quote['line_start']}-{quote['line_end']}"
                })
                node_ids.add(quote['id'])
            
            # Add entity nodes and edges
            for entity in quote.get('entities', []):
                entity_id = f"entity_{entity['id']}"
                if entity_id not in node_ids:
                    nodes.append({
                        "id": entity_id,
                        "label": entity['name'],
                        "type": "entity",
                        "entity_type": entity['entity_type'],
                        "confidence": entity.get('confidence', 0)
                    })
                    node_ids.add(entity_id)
                
                # Add edge from quote to entity
                edges.append({
                    "source": quote['id'],
                    "target": entity_id,
                    "type": "MENTIONS",
                    "confidence": entity.get('confidence', 0)
                })
            
            # Add code nodes and edges
            for code in quote.get('codes', []):
                code_id = f"code_{code['id']}"
                if code_id not in node_ids:
                    nodes.append({
                        "id": code_id,
                        "label": code['name'],
                        "type": "code",
                        "code_type": code.get('code_type', 'code'),
                        "confidence": code.get('confidence', 0)
                    })
                    node_ids.add(code_id)
                
                # Add edge from quote to code
                edges.append({
                    "source": quote['id'],
                    "target": code_id,
                    "type": "SUPPORTS",
                    "confidence": code.get('confidence', 0)
                })
        
        # Network statistics
        network_stats = {
            "node_count": len(nodes),
            "edge_count": len(edges),
            "quote_nodes": len([n for n in nodes if n['type'] == 'quote']),
            "entity_nodes": len([n for n in nodes if n['type'] == 'entity']),
            "code_nodes": len([n for n in nodes if n['type'] == 'code']),
            "generated_at": datetime.utcnow().isoformat()
        }
        
        return {
            "nodes": nodes,
            "edges": edges,
            "statistics": network_stats,
            "metadata": {
                "generator": "Automated Qualitative Coding System",
                "format": "cytoscape_json",
                "compatible_with": ["Cytoscape", "Gephi", "NetworkX", "D3.js"],
                "node_types": ["quote", "entity", "code"],
                "edge_types": ["MENTIONS", "SUPPORTS"]
            }
        }
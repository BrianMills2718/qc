{
  "codes": [
    {
      "id": "A1",
      "name": "AI Applications in Research Methods",
      "description": "This code captures discussions about specific ways AI tools are or could be applied to various stages and tasks within the research process, from data collection and analysis to proposal writing and project management.",
      "semantic_definition": "The practical implementation and utility of artificial intelligence technologies to augment or automate tasks inherent in academic and policy research methodologies.",
      "parent_id": null,
      "level": 1,
      "example_quotes": [
        "I've been using some of the LLM's for. And kind of more exploring some of their. Thematic coding and kind of ability to kind of group documents then generate text for me",
        "I have used AI tools to help with my code. I know in general how to execute one of these methods but sometime there are new packages written but my code is having errors so I can take the code and put it in an LLM; can you fix this error or can you write this more concisely?",
        "I’ve also done things for proposal writing and taken my idea where I want to use a particular design and poke holes in this; What are the problems with this; how can I strengthen this?",
        "Like Can you imagine? A world where, like AI could feed in information about the kind of participants you're looking for. And AI could crawl the Internet to find them. Invite them to participate and then find a time on your calendar for the interview."
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "A1.1",
      "name": "Transcription & Summarization",
      "description": "Use of AI for converting spoken language into text and generating concise summaries of content.",
      "semantic_definition": "The application of AI, particularly speech-to-text and natural language processing, to automate the conversion of audio/video recordings into written transcripts and to condense longer texts into shorter forms.",
      "parent_id": "A1",
      "level": 2,
      "example_quotes": [
        "I've been doing the kind of machine transcription and stuff",
        "Otter? That tool is used for research. Providers and patients and they are using Otter to take notes and it transcribes and summarizes."
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "A1.2",
      "name": "Qualitative Data Coding & Analysis",
      "description": "Application of AI to assist with or automate the process of identifying, categorizing, and analyzing themes within qualitative data such as interview transcripts or focus group discussions.",
      "semantic_definition": "The utilization of AI algorithms, including large language models, to perform thematic coding, categorization, and pattern recognition on unstructured qualitative datasets, aiming to streamline or enhance human qualitative analysis.",
      "parent_id": "A1",
      "level": 2,
      "example_quotes": [
        "I've been using some of the LLM's for. And kind of more exploring some of their. Thematic coding and kind of ability to kind of group documents",
        "I'm trying to code like 12 specific themes in all the documents and the themes aren't particularly rare... and I'm looking for like patterns of correlation... So that's where I'll turn to like a machine to get it done.",
        "Interview coding, something way better than Dedoose. We do a lot of interviews and the coding is uneven in quality. So it would be great if we had some standard way to do that and a tool to help with that."
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "A1.3",
      "name": "Literature Review & Information Retrieval",
      "description": "Use of AI to search, filter, summarize, and extract information from academic literature and large document sets for research purposes.",
      "semantic_definition": "The deployment of AI, particularly natural language processing and machine learning, to automate or assist in the systematic identification, screening, data extraction, and synthesis of relevant scholarly articles and documents for literature reviews and environmental scans.",
      "parent_id": "A1",
      "level": 2,
      "example_quotes": [
        "I don’t … where you write a code, a specific LLM for your project to sift through hundreds of pages of information to pull out what is most relevant.",
        "We did try to like use one of those, like elicit. I think it was called to see like whether it was. As accurate as our Ra's.",
        "We did write a python script to use the RAND CHAT to review a bunch of papers. So we did the literature review and had it spit out in a spreadsheet a once sentence summary of the paper or we asked it questions, is this paper based in the US?",
        "I think there are really good use case, tools related to literature reviews, environmental scans, that is really good."
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "A1.4",
      "name": "Proposal Development & Writing",
      "description": "Application of AI tools to assist in drafting, refining, and strengthening research proposals, including generating summaries or identifying weaknesses.",
      "semantic_definition": "The leveraging of AI, specifically large language models, to aid in the ideation, structuring, content generation, and critical review of research proposals, enhancing their clarity, completeness, and persuasive power.",
      "parent_id": "A1",
      "level": 2,
      "example_quotes": [
        "I’ve also done things for proposal writing and taken my idea where I want to use a particular design and poke holes in this; What are the problems with this; how can I strengthen this?",
        "How helpful are LLM’s for proposals. I take the whole proposal and say write an executive summary; it is great at doing that",
        "I’ve played a little with telling it to, to make an image for proposal. Somewhere you can say, I want something that looks like an experiment but relevant to labor markets."
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "A1.5",
      "name": "Code Generation & Debugging",
      "description": "Use of AI to write, convert, or identify and fix errors in programming code used for data analysis or other research tasks.",
      "semantic_definition": "The employment of AI, particularly large language models, to assist researchers in generating new programming code, translating code between languages, or identifying and rectifying errors within existing codebases.",
      "parent_id": "A1",
      "level": 2,
      "example_quotes": [
        "I have used AI tools to help with my code. I know in general how to execute one of these methods but sometime there are new packages written but my code is having errors so I can take the code and put it in an LLM; can you fix this error or can you write this more concisely?",
        "I found someone else’s code and asked can you convert this R code to Stata code and kept playing with it and learned what is good and not good.",
        "The time-consuming process of pulling data down, checking code. So one thing when I feed it in and there is an error, but then you can use the ai tools to check the code, annotate the code, replicability those are time consuming and for AI."
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "A1.6",
      "name": "Recruitment & Participant Identification",
      "description": "Potential use of AI to identify, contact, and schedule research participants, particularly for interviews and focus groups.",
      "semantic_definition": "The hypothetical application of AI to automate or streamline the process of identifying suitable individuals or organizations for research participation, outreach, and scheduling, thereby reducing the logistical burden of recruitment.",
      "parent_id": "A1",
      "level": 2,
      "example_quotes": [
        "I think finding people maybe supporting scheduling like that kind of thing feels like like AI could nail that out of the park.",
        "Like Can you imagine? A world where, like AI could feed in information about the kind of participants you're looking for. And AI could crawl the Internet to find them. Invite them to participate and then find a time on your calendar for the interview.",
        "Even that like, the way that I kind of you know start some projects now or just trying to identify you know who the best partners are (for a grant submission) or the best organizations for inroads into a population that you want to reach."
      ],
      "discovery_confidence": 0.85
    },
    {
      "id": "A1.7",
      "name": "Virtual Simulations & Population Modeling",
      "description": "The concept of using AI to create virtual populations or simulated environments for testing research tools, surveys, or policy interventions before real-world application.",
      "semantic_definition": "The innovative use of AI to construct synthetic populations or dynamic simulated environments, programmed with specific characteristics, to serve as a \"sandbox\" for pre-testing research instruments, methodologies, or policy scenarios, thereby reducing the need for immediate real-world experimentation.",
      "parent_id": "A1",
      "level": 2,
      "example_quotes": [
        "Something that I've been thinking about that would be super helpful if it was possible for researchers is the idea like we have our ALP panels. You know of people and something I was thinking about would be if we could take those panels and almost for like each person develop an AI agent of that person program it with like personality traits, you know, or maybe even just make it like if we could just basically create virtual populations in essence.",
        "If there was something like something virtual like that, it's feel like as researchers would be like this, you know, kind of like a place like a sandbox to play in before we go out and and maybe test tools in the real world."
      ],
      "discovery_confidence": 0.8
    },
    {
      "id": "A1.8",
      "name": "Institutional Knowledge Leverage",
      "description": "Using AI to access, synthesize, and apply an organization's vast internal knowledge base (e.g., past reports, recommendations, partner networks) to inform current and future research.",
      "semantic_definition": "The strategic application of AI to systematically mine and integrate an organization's cumulative internal data, including historical research outputs, recommendations, and collaborative networks, to enhance situational awareness, avoid redundant efforts, and improve the feasibility and relevance of new research initiatives.",
      "parent_id": "A1",
      "level": 2,
      "example_quotes": [
        "Even just inputting all of Rand's past projects and who their partners are and like what they did, and having an AI crawl through all of that like, I feel like there's a lot of good leads that like across Rand.",
        "If there's some way for AI to like, take all of our reports and our recommendations. And Help us to become more situationally aware of things that we've already recommended that might have come out as not being implemented because there's a barrier that prevents that like it would be nice to be able to like reality. Check our recommendations from different reports with like. What we know are known implementation issues",
        "people sometimes ask me \"What does RAND think about X\" and after i explain RAND isn't a monolith and has no actual opinions and doesnt advocate anyway, i still dont know what we may have previously recommended about something"
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "B1",
      "name": "Perceived Benefits of AI",
      "description": "This code encompasses the positive impacts and advantages that researchers identify or anticipate from the adoption and use of AI in their work.",
      "semantic_definition": "The identified or anticipated positive outcomes, efficiencies, and strategic advantages that artificial intelligence technologies offer to enhance the research process and its outputs.",
      "parent_id": null,
      "level": 1,
      "example_quotes": [
        "I think finding people maybe supporting scheduling like that kind of thing feels like like AI could nail that out of the park.",
        "I think there are really good use case, tools related to literature reviews, environmental scans, that is really good.",
        "it is speeding things up for ppl in a way that makes me feel I don’t want to be left behind"
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "B1.1",
      "name": "Efficiency & Time Savings",
      "description": "AI's ability to reduce the time and effort required for various research tasks, leading to increased productivity.",
      "semantic_definition": "The capacity of AI to streamline research workflows, automate repetitive or time-consuming tasks, and thereby reduce the overall effort and duration required for project completion.",
      "parent_id": "B1",
      "level": 2,
      "example_quotes": [
        "I'm an implementation scientist. Have been really interested in thinking about. The role that AI plays in implementation science, but also. Vice versa, the implementation of AI in science. So I'm also like the global scholar in translation and have been focused a lot on how. We can translate our research better and more efficiently, and obviously AI has been part of the of what I've been thinking about in terms of that",
        "We can use AI for a literature review that would have taken a RA 20 days so benefits of cost savings",
        "it is speeding things up for ppl in a way that makes me feel I don’t want to be left behind"
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "B1.2",
      "name": "Enhanced Data Handling",
      "description": "AI's capability to process, organize, and extract insights from large or complex datasets more effectively than traditional methods.",
      "semantic_definition": "The improved capacity, facilitated by AI, to manage, analyze, and derive meaningful information from extensive, diverse, or unstructured data sources, including text, numerical, and observational data.",
      "parent_id": "B1",
      "level": 2,
      "example_quotes": [
        "I'm trying to code like 12 specific themes in all the documents and the themes aren't particularly rare... and I'm looking for like patterns of correlation... So that's where I'll turn to like a machine to get it done.",
        "The time-consuming process of pulling data down, checking code. So one thing when I feed it in and there is an error, but then you can use the ai tools to check the code, annotate the code, replicability those are time consuming and for AI.",
        "I think with like within the literature review it depends on. What? Your like to really, I think what AI could do is help us do a better job at the less obvious tasks relating to searching that would allow for more complex like cross disciplinary and like digging into deeper wells and pockets to find insights that are relevant."
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "B1.3",
      "name": "Improved Research Design & Quality",
      "description": "The potential for AI to contribute to more robust research designs, more accurate findings, and more feasible recommendations.",
      "semantic_definition": "The capacity of AI to enhance the rigor, validity, and practical applicability of research by assisting in the refinement of methodologies, the generation of more precise forecasts, and the alignment of recommendations with real-world constraints.",
      "parent_id": "B1",
      "level": 2,
      "example_quotes": [
        "I’ve also done things for proposal writing and taken my idea where I want to use a particular design and poke holes in this; What are the problems with this; how can I strengthen this?",
        "If we could forecast more accurately in the outset then we could have more accurate recommendations than competitors.",
        "If there's some way for AI to like, take all of our reports and our recommendations. And Help us to become more situationally aware of things that we've already recommended that might have come out as not being implemented because there's a barrier that prevents that like it would be nice to be able to like reality. Check our recommendations from different reports with like. What we know are known implementation issues"
      ],
      "discovery_confidence": 0.85
    },
    {
      "id": "B1.4",
      "name": "Competitive Advantage",
      "description": "The strategic benefit AI can provide to an organization, allowing it to outperform competitors or maintain its market position.",
      "semantic_definition": "The strategic leverage gained by an organization through the effective adoption and innovative application of AI, enabling it to deliver superior research products, services, or insights compared to its rivals, thereby securing or enhancing its market standing.",
      "parent_id": "B1",
      "level": 2,
      "example_quotes": [
        "How do we make sure we don’t get put out of business in that environment. How do we maintain a competitive edge. There are ways we do that to develop propriety tools but that day is coming very quickly.",
        "If we could forecast more accurately in the outset then we could have more accurate recommendations than competitors.",
        "just from a business development standpoint, if you would seem like. I mean. Competitors would be doing it."
      ],
      "discovery_confidence": 0.85
    },
    {
      "id": "C1",
      "name": "Perceived Challenges & Risks of AI",
      "description": "This code covers the difficulties, limitations, and potential negative consequences or concerns that researchers associate with the use and adoption of AI in their work.",
      "semantic_definition": "The identified obstacles, inherent limitations, and potential adverse outcomes or ethical dilemmas associated with the integration and reliance on artificial intelligence within the research ecosystem.",
      "parent_id": null,
      "level": 1,
      "example_quotes": [
        "it was difficult for me to like a just inherently trust what it was spitting out in a way that maybe you want to just like take it and use it to draw further conclusions.",
        "the risk is that we will end up utilizing AI for stuff our junior folks used to do. We can use AI for a literature review that would have taken a RA 20 days so benefits of cost savings but I worry about career development and skillset development among the younger folks.",
        "I don’t want to inadvertently take someone else’s intellectual property."
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "C1.1",
      "name": "Accuracy & Trust Issues",
      "description": "Concerns about the reliability, factual correctness, and trustworthiness of AI-generated outputs, including \"hallucinations\" or fabricated information.",
      "semantic_definition": "The inherent skepticism or demonstrated unreliability of AI outputs, stemming from issues such as factual inaccuracies, fabricated information (\"hallucinations\"), or inconsistencies, which necessitate human verification and limit full confidence in AI-generated content.",
      "parent_id": "C1",
      "level": 2,
      "example_quotes": [
        "it was difficult for me to like a just inherently trust what it was spitting out in a way that maybe you want to just like take it and use it to draw further conclusions.",
        "it missed anything that was nuanced. It sort of wasn't picking up on things. I say this as someone who's sort of AI naive like I I'm sure I could have programmed it better or given it better prompts. Or asked in different ways, but at that point I feel like it's faster to just do it myself",
        "I asked an LLM for something and explicitly asked to NOT make up references, and it still made up a reference. so i need to really see good evidence that i can trust it before using for lit reviews",
        "I would ask RAND CHAT, are there systematic studies on blah or what do you know about x and y and it would give me papers/citations that were not real. So I always check."
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "C1.2",
      "name": "Loss of Nuance & Context",
      "description": "AI's difficulty in capturing subtle meanings, underlying contexts, or complex human interactions, particularly in qualitative data analysis.",
      "semantic_definition": "The limitation of AI in fully comprehending and representing the subtle complexities, implicit meanings, and socio-political contexts embedded within qualitative data or human communication, leading to potentially superficial or misleading interpretations.",
      "parent_id": "C1",
      "level": 2,
      "example_quotes": [
        "we found when you know going back and rereading it, that there were definitely, like, nuances that were missed and things that, you know were not picked up that were relevant to our project. Especially because this project is like really politically sensitive",
        "it missed anything that was nuanced. It sort of wasn't picking up on things.",
        "AI can't replace us in reading transcripts and understanding the context behind the interview in understanding the conversation.",
        "you can’t trust it but sometimes stuff that is off and misses nuance"
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "C1.3",
      "name": "Job Displacement & Skill Development",
      "description": "Concerns that AI automation may reduce the need for human researchers, particularly junior staff, and impact their career development and skill acquisition.",
      "semantic_definition": "The apprehension that AI's increasing automation of research tasks may lead to a reduction in human employment opportunities, particularly for entry-level positions, and potentially hinder the development of essential research skills among junior professionals.",
      "parent_id": "C1",
      "level": 2,
      "example_quotes": [
        "The risk is that we will end up utilizing AI for stuff our junior folks used to do. We can use AI for a literature review that would have taken a RA 20 days so benefits of cost savings but I worry about career development and skillset development among the younger folks.",
        "I feel like every suggestion I'm making is like putting someone out of a job.",
        "Maybe we're in a very maybe our concerns about losing our jobs are not, so maybe it'll just corrupt itself so quickly that we come back in vogue."
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "C1.4",
      "name": "Intellectual Property & Data Security",
      "description": "Concerns about AI models potentially using proprietary or sensitive data without permission, or generating content that infringes on existing intellectual property rights.",
      "semantic_definition": "The apprehension regarding AI's potential to compromise data confidentiality, utilize sensitive or proprietary information without authorization, or produce outputs that inadvertently or intentionally infringe upon existing intellectual property rights, raising legal and ethical concerns.",
      "parent_id": "C1",
      "level": 2,
      "example_quotes": [
        "My sense is the Army thinks our competitors are integrating AI wholistically. Secretary of the Army wants Palantir and not RAND. Palantir would be doing things on our data. So we think there is a risk to our research being utilized opportunistically by AI company to get ahead and to put us out of business.",
        "I don’t want to inadvertently take someone else’s intellectual property. Saw a thing on john Oliver, ppl making images, based on what is in the public and making something new so it is kind of stealing. I don’t want to take anyone’s intellectual property.",
        "But if I were to take my proposal and say write this, is it going to take texts from others?"
      ],
      "discovery_confidence": 0.85
    },
    {
      "id": "C1.5",
      "name": "Red Queen\" Scenario",
      "description": "The concept that widespread AI adoption might lead to a competitive treadmill where everyone runs faster just to stay in the same place, without achieving significant net gains.",
      "semantic_definition": "An evolutionary analogy applied to AI adoption, positing that as competitors universally adopt AI to gain an advantage, the net effect is merely an acceleration of activity without a corresponding increase in relative standing or overall benefit, akin to running faster just to remain in the same position.",
      "parent_id": "C1",
      "level": 2,
      "example_quotes": [
        "I think somebody actually people aren't anticipating about AI development is some of this technology will be like a red Queen scenario. So you're just running faster and faster. So in the red Queen's running faster and faster to stay in the same place like on a treadmill.",
        "because your competitors start doing it. I mean, like you're saying, I'm gonna get all these more proposals submitted faster, right? But everyone else is gonna do that. And so then you're just you see what I mean? There's no actual net. Everyone stays where they are.They're just all going faster now"
      ],
      "discovery_confidence": 0.8
    },
    {
      "id": "C1.6",
      "name": "Ethical & Societal Impacts",
      "description": "Broader concerns about the long-term implications of AI, including its potential to perpetuate misinformation, influence human consciousness, or create unforeseen societal challenges.",
      "semantic_definition": "The broader moral, philosophical, and societal concerns arising from the pervasive integration of AI, encompassing issues such as the perpetuation of biased or erroneous information, the potential for AI to develop consciousness, and other unforeseen systemic risks to human well-being and social structures.",
      "parent_id": "C1",
      "level": 2,
      "example_quotes": [
        "as AI continues to create more content. And it like feeds itself and and it's basing that content on some right stuff and some wrong stuff. So it's perpetuating some wrong stuff and it just keeps getting bigger and bigger like it gets it just. It's like feeding itself.",
        "I think isn't the theory like one theory of consciousness is that consciousness arises from like self referential loops. And so I feel like we have a lot more to worry about joy than just losing our jobs.",
        "I just have lots of opinions about its potential negative impacts on humans and society"
      ],
      "discovery_confidence": 0.8
    },
    {
      "id": "D1",
      "name": "AI Adoption & Integration",
      "description": "This code captures discussions related to the broader organizational strategy, challenges, and requirements for effectively integrating AI tools and practices into research institutions like RAND.",
      "semantic_definition": "The strategic considerations, organizational hurdles, and necessary infrastructure or cultural shifts involved in the widespread implementation and seamless incorporation of artificial intelligence technologies within a research-oriented institution.",
      "parent_id": null,
      "level": 1,
      "example_quotes": [
        "I think based on the professional conference I went to, I think we might be a little bit slower [level of adoption], whether that is right I don’t know. I personally feel others are using this and I should… it is speeding things up for ppl in a way that makes me feel I don’t want to be left behind but I feel a little about it.",
        "Need to be company wide ai initiatives that every unit and division are asked to participate in.",
        "There could be more along those lines, showcasing how ppl use it successfully. A little bit but not a ton and someone super savvy and using it a lot could give a rundown of how they use it day to day."
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "D1.1",
      "name": "Barriers to Adoption",
      "description": "Factors hindering the widespread or effective integration of AI tools and practices within a research organization.",
      "semantic_definition": "The identified obstacles, including lack of trust, insufficient training, cost implications, or organizational policies, that impede the broad and effective implementation of AI technologies within a research environment.",
      "parent_id": "D1",
      "level": 2,
      "example_quotes": [
        "it was difficult for me to like a just inherently trust what it was spitting out",
        "I don’t know how to get it to do what I want it to.",
        "To be honest I am not sure, I don’t know if ppl feel like they are not supposed to use these bc I know RAND has its own specific rand chat and rand came out and said don’t use something, so part of me wonders if ppl are hesitant for that reason.",
        "if you are coding work that classified."
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "D1.2",
      "name": "Need for Training & Guidance",
      "description": "The perceived necessity for educational programs, best practices, and clear guidelines to help researchers effectively and responsibly use AI tools.",
      "semantic_definition": "The recognized requirement for structured educational initiatives, practical demonstrations, and clear policy frameworks to equip researchers with the knowledge, skills, and ethical understanding necessary for competent and responsible utilization of AI technologies.",
      "parent_id": "D1",
      "level": 2,
      "example_quotes": [
        "I say this as someone who's sort of AI naive like I I'm sure I could have programmed it better or given it better prompts. Or asked in different ways",
        "I feel like this is the type of thing we are not read in enough on it.",
        "There could be more along those lines, showcasing how ppl use it successfully. A little bit but not a ton and someone super savvy and using it a lot could give a rundown of how they use it day to day."
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "D1.3",
      "name": "Organizational Strategy & Policy",
      "description": "Discussions about how an organization like RAND should strategically approach AI adoption, including company-wide initiatives, competitive positioning, and internal governance.",
      "semantic_definition": "The high-level planning and formal directives concerning an organization's approach to AI integration, encompassing decisions on investment, competitive differentiation, internal usage guidelines, and the establishment of company-wide initiatives to ensure responsible and effective AI deployment.",
      "parent_id": "D1",
      "level": 2,
      "example_quotes": [
        "How do we promote responsible adoption? If we are read in enough on it. I feel like this is the type of thing we are not read in enough on it. The way AI adoption happens is stovepipped and a lot of the discussion is in GER, so in QA process, I will like, if someone utilized RANDCHAT (to write their report) to make sure that is not happening.",
        "Need to be company wide ai initiatives that every unit and division are asked to participate in.",
        "I think based on the professional conference I went to, I think we might be a little bit slower [level of adoption], whether that is right I don’t know. I personally feel others are using this and I should… it is speeding things up for ppl in a way that makes me feel I don’t want to be left behind but I feel a little about it."
      ],
      "discovery_confidence": 0.9
    }
  ],
  "total_codes": 25,
  "hierarchy_depth": 2,
  "discovery_method": "Thematic Analysis",
  "analytic_question": "How do researchers perceive AI's impact on their work?",
  "extraction_confidence": 0.95
}
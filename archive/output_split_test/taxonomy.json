{
  "codes": [
    {
      "id": "challenges_traditional_qual_research",
      "name": "Challenges in Traditional Qualitative Research",
      "description": "Difficulties encountered in standard qualitative research methods (interviews, focus groups, literature reviews) that are time-consuming, labor-intensive, or require specialized skills.",
      "semantic_definition": "This code captures the inherent pain points and inefficiencies in conventional qualitative research methodologies, setting the stage for where AI might offer solutions.",
      "parent_id": null,
      "level": 1,
      "example_quotes": [],
      "discovery_confidence": 0.95
    },
    {
      "id": "recruitment_challenges",
      "name": "Recruitment Challenges",
      "description": "Difficulties in identifying, contacting, and securing participation from suitable individuals or groups for interviews and focus groups.",
      "semantic_definition": "This code refers to the logistical and practical hurdles in assembling a representative or target-specific sample for qualitative data collection.",
      "parent_id": "challenges_traditional_qual_research",
      "level": 2,
      "example_quotes": [
        "Finding the right people and recruiting them.",
        "Yeah, definitely like getting getting the sample, especially if they're not spoon fed to you. Like often times we get on the military side where we get a list of contacts from the sponsor to call.",
        "I mean in healthcare, it's hard to get providers.",
        "Oh yeah, physicians can be a nightmare.",
        "Yeah. And then second to that would be patients.",
        "I find recruitment to be the hardest part and also like this story for another time. I mean, I have stories of my own spectacular recruitment failures, right?"
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "data_coding_analysis_burden",
      "name": "Data Coding and Analysis Burden",
      "description": "The labor-intensive and time-consuming nature of manually coding large volumes of qualitative data (e.g., interview transcripts, documents) and tabulating themes.",
      "semantic_definition": "This code encompasses the significant effort and time required for systematic categorization, interpretation, and quantification of qualitative data, often cited as a major bottleneck.",
      "parent_id": "challenges_traditional_qual_research",
      "level": 2,
      "example_quotes": [
        "Coding large amounts of data.",
        "Coding Is very annoying.",
        "For example, I was just on a project. We interviewed 30 physicians, which doesn't sound like that much, but the interviews were an hour long and pretty dense. And I was tasked with doing them in deduce and it just takes forever. And it's not the most like compelling task. So I would say that's a point of frustration. It's like my least favorite part of the project.",
        "Yeah, I was gonna get too, Todd, if you asked what the most difficult one I was thinking about my least favorite one, which I think is what Sarah said (coding).",
        "And I mean it takes the longest also. And then I think one thing that you were alluding to, Sarah, but I'm not sure if you what was your experience is that it's a lot harder for me to do the analysis if I wasn't the one if I wasn't the one who was taking notes.",
        "Thinking about the frequency of the post and of the themes (so analyzing statistics around coded content), Like these are the most mentioned themes. Is like this concept mentioned four of the 10 interviews.",
        "So tabulating, tabulating the frequency of of of comments and topics."
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "literature_review_inefficiencies",
      "name": "Literature Review Inefficiencies",
      "description": "The challenges and time-consuming aspects of conducting comprehensive and rigorous literature reviews, including search strategy development, data extraction, and identifying nuanced or cross-disciplinary relevant sources.",
      "semantic_definition": "This code refers to the practical difficulties in systematically identifying, organizing, and synthesizing existing scholarly work, particularly concerning search precision, scope, and the manual effort involved in data compilation.",
      "parent_id": "challenges_traditional_qual_research",
      "level": 2,
      "example_quotes": [
        "I mean, I feel like at rand there's a million different ways to do literature reviews, and I imagine you've all had to do them. And and you know, they vary from sort of shoot from the hip, write a couple pages in your background section to to more rigorous Systematic reviews",
        "How often do you all like rely on spreadsheets to draft your literature reviews, in other words? Create a spreadsheet with 10 or 1520 variables and then having Raas or whoever go through reports and then systematically filling in those those data holes on the spreadsheets.",
        "That's pretty much how I do it. Maybe it's old school, but. We did try to like use one of those, like elicit. I think it was called to see like whether it was. As accurate as our Ra's. But it got like expensive quickly and we when we looked at the side by side comparison between what RA’s extracted and what Elicit did, there were some inconsistencies, I think.",
        "I don't usually do that with literature, but I would think with AI you would have to like do that. Something similar in order to use it with confidence.",
        "the one thing that I don't know how to still do well myself, but I always have to rely on the librarian for. It's like all of the search strategy stuff like 'cause like they know all of the typologies of how language works in all of the different databases, and so what are the right search terms depending on what you're looking for and when to use the “and” and “or” and like. All of that, the search architecture. Feels like there's, like, you know, probably an AI solution to that, but.",
        "I feel like there are some relevant pieces of literature that get overlooked when searching for literature because they don't have certain words in the title or the abstract, but they are in fact spot on.",
        "I feel like sometimes like that's like a very human thing to do is say there's like a parallel study area that is this, that you're not gonna get by searching, like what you would normally put in your search terms. But it is very aligned and relevant.",
        "I guess like a lot of the way that I end up being or something like 100 or thousand more lists of abstract or papers from keyword search and maybe I don’t need all of it, but it's really clear (why the search results produced so many abstracts) because there's some word in the title that you know matches so. As soon as it could be easy enough to to try to like just remove those (unnecessary or irrelevant abstracts) and then and then you would be a lot more specific, I guess."
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "ai_applications_benefits",
      "name": "AI Applications and Potential Benefits",
      "description": "Specific ways AI tools are currently being used or could be used to enhance efficiency, accuracy, or scope in qualitative research and related research processes.",
      "semantic_definition": "This code captures the perceived advantages and practical applications of AI technologies in streamlining, augmenting, or innovating various stages of qualitative research and broader research operations.",
      "parent_id": null,
      "level": 1,
      "example_quotes": [],
      "discovery_confidence": 0.95
    },
    {
      "id": "ai_data_processing_transcription",
      "name": "AI for Data Processing and Transcription",
      "description": "The use of AI for automated transcription of interviews/focus groups and initial processing of large datasets.",
      "semantic_definition": "This code refers to AI's utility in converting spoken language to text and handling initial data organization, reducing manual effort in foundational data preparation.",
      "parent_id": "ai_applications_benefits",
      "level": 2,
      "example_quotes": [
        "I've been doing the kind of machine transcription and stuff",
        "I have to go through like you know the same way you get Adobe Pro, Acrobat or whatever. OK. See, I'm always learning stuff. Do you think it's more accurate?"
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "ai_thematic_coding_analysis",
      "name": "AI for Thematic Coding and Analysis",
      "description": "The application of AI, particularly LLMs, for identifying themes, grouping documents, and generating summaries from qualitative data.",
      "semantic_definition": "This code captures AI's capability to automate or assist in the interpretive process of qualitative data, identifying patterns and synthesizing information, potentially speeding up analysis.",
      "parent_id": "ai_applications_benefits",
      "level": 2,
      "example_quotes": [
        "I particularly did a bunch of that around like. Like traditional theme coding. So like where you're coding themes and documents and then you just make a machine that is like a virtual coder that uses training data from a person to just hit those structured codes the same way.",
        "And then lately I have been using some of the the LLM side. So besides like the auto, I've been doing the kind of machine transcription and stuff, but I've been using some of the LLM's for. And kind of more exploring some of their. Thematic coding and kind of ability to kind of group documents then generate text for me or you know, I'm kind of old school about that.",
        "I have a couple papers where one where we're comparing. Directly, like the LLM for this kind of theme coding to supervise machine learning to humans.",
        "I mean, that's sort of a different side of the same coin, right? Is is reviewing documents and parceling out information from documents. But like when you're doing that, are you looking for needles in the haystack? Are you trying to code all the documents or look for specific information across all of them to see which ones? Which small number might be relevant?",
        "Yeah, I've done both, but I've done plenty of ones where like the one right now at the 20,000 I'm trying to code like 12 specific themes in all the documents and the themes aren't particularly rare. You know, maybe they occur in each theme, maybe occurs in 20 percent of the documents and I'm looking for like patterns of correlation. You see what I mean between the themes across the documents?",
        "expert lens and expert lenses, integrating AI now to kind of go through and give a synopsis of what everybody says for the different questions or topics that you're asking about."
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "ai_recruitment_partner_identification",
      "name": "AI for Recruitment and Partner Identification",
      "description": "The potential use of AI to identify and recruit research participants, schedule interviews, and find suitable organizational partners for projects.",
      "semantic_definition": "This code highlights AI's prospective role in automating and optimizing the initial outreach and logistical phases of research, leveraging vast data to connect researchers with relevant individuals and entities.",
      "parent_id": "ai_applications_benefits",
      "level": 2,
      "example_quotes": [
        "finding people maybe supporting scheduling like that kind of thing feels like like AI could nail that out of the park.",
        "Like Can you imagine? A world where, like AI could feed in information about the kind of participants you're looking for. And AI could crawl the Internet to find them. Invite them to participate and then find a time on your calendar for the interview. Period.",
        "I kind of you know start some projects now or just trying to identify you know who the best partners are (for a grant submission) or the best organizations for inroads into a population that you want to reach. And sometimes that can be really difficult too. And you know, a lot of times I just start with Google. But, you know, having AI, being able to give you this landscape of groups and orgs and. You know, you know at least where to start in the field. It's something I think would be really helpful.",
        "Even just inputting all of Rand's past projects and who their partners are and like what they did, and having an AI crawl through all of that like, I feel like there's a lot of good leads that like across Rand."
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "ai_literature_review_enhancement",
      "name": "AI for Literature Review Enhancement",
      "description": "The application of AI to improve the efficiency and comprehensiveness of literature reviews, particularly in search strategy, filtering irrelevant results, and identifying nuanced connections.",
      "semantic_definition": "This code refers to AI's potential to refine the process of synthesizing existing knowledge by optimizing search parameters, reducing noise in results, and uncovering less obvious but relevant scholarly contributions.",
      "parent_id": "ai_applications_benefits",
      "level": 2,
      "example_quotes": [
        "I think that a this AI stuff and machine learning in general is gonna be like it's gonna become a part of literature views in different ways for like different. Like you say different styles and levels of precision of literature view",
        "the one thing that I don't know how to still do well myself, but I always have to rely on the librarian for. It's like all of the search strategy stuff like 'cause like they know all of the typologies of how language works in all of the different databases, and so what are the right search terms depending on what you're looking for and when to use the “and” and “or” and like. All of that, the search architecture. Feels like there's, like, you know, probably an AI solution to that, but.",
        "I feel like there are some relevant pieces of literature that get overlooked when searching for literature because they don't have certain words in the title or the abstract, but they are in fact spot on.",
        "I think what AI could do is help us do a better job at the less obvious tasks relating to searching that would allow for more complex like cross disciplinary and like digging into deeper wells and pockets to find insights that are relevant.",
        "But that seems uniquely suited to large language models.",
        "As soon as it could be easy enough to to try to like just remove those (unnecessary or irrelevant abstracts) and then and then you would be a lot more specific, I guess.",
        "it would be really great to be Able to iterate like interactively to strip those out or to like be able to feed some of the those kind of considerations. Then, like if you're doing. … Feed those considerations in on the front end or to iterate on the pool of literature that you're trying to like, sharpen focus like you want to whittle down window down or whatever in that way."
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "ai_organizational_knowledge_management",
      "name": "AI for Organizational Knowledge Management",
      "description": "The potential use of AI to synthesize and make accessible an organization's vast internal knowledge base, such as past reports, recommendations, and project outcomes, to inform future research and decision-making.",
      "semantic_definition": "This code refers to AI's capability to act as an intelligent repository and retrieval system for institutional memory, enabling researchers to leverage prior work, avoid redundant recommendations, and ensure feasibility of new proposals.",
      "parent_id": "ai_applications_benefits",
      "level": 2,
      "example_quotes": [
        "if there's some way for AI to like, take all of our reports and our recommendations. And Help us to become more situationally aware of things that we've already recommended that might have come out as not being implemented because there's a barrier that prevents that like it would be nice to be able to like reality. Check our recommendations from different reports with like. What we know are known implementation issues so that we're not like recommending something that's not feasible Based on somebody else's study at Rand, right.",
        "I feel like there's a way, a better way for us to, like create virtual Systems environments. So it's not like ALP ING like a person. It would be like. Creating and again this is like where the my experience with like how to set this up is limited like setting up like a a virtual like DoD where you got different you got your different departments and you've got our wealth of knowledge about each of those departments and. You can say, OK, if I said to do this, How likely is that to work? Or if I want to work Air Force and army in this way together, what do we know about what's worked in the past",
        "even if it's simply like, oh, someone's already recommended this before. That would even be useful to know such that you're not.",
        "people sometimes ask me \"What does RAND think about X\" and after i explain RAND isn't a monolith and has no actual opinions and doesnt advocate anyway, i still dont know what we may have previously recommended about something"
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "ai_virtual_population_simulation",
      "name": "AI for Virtual Population Simulation",
      "description": "The concept of creating AI agents or virtual populations, potentially based on existing panels like ALP, to simulate responses for survey or focus group testing before real-world deployment.",
      "semantic_definition": "This code refers to the innovative idea of using AI to construct synthetic populations that mimic real-world demographics and behaviors, serving as a \"sandbox\" for pre-testing research instruments and methodologies.",
      "parent_id": "ai_applications_benefits",
      "level": 2,
      "example_quotes": [
        "the idea like we have our ALP panels. You know of people and something I was thinking about would be if we could take those panels and almost for like each person develop an AI agent of that person program it with like personality traits, you know, or maybe even just make it like if we could just basically create virtual populations in essence.",
        "Like assign an agent an AI agent to each participant in the ALP panel.",
        "And then once you have those agents, if you basically like you know, gave them a survey similar to what we've done in ALP, would they respond in the same way that we might expect given like certain characteristics and backgrounds of, you know, people like each agent would be? Programmed with like socio demographic characteristics or personality characteristics, etcetera. And if there was something like something virtual like that, it's feel like as researchers would be like this, you know, kind of like a place like a sandbox to play in before we go out and and maybe test tools in the real world.",
        "Like instead of doing you know like looking like getting small focus groups do like content validity on our like focus group like interviews and things like that we could you know give it to like a virtual population.",
        "I've heard this mention before and I do think like the ALP is something that like outside of Rand, people like buy from us essentially. You know what I mean? Like they use our AOP in their research as well. And so I don't know if they're thinking about this, but I'm, I'm sure various alternative survey panels will be providing this like a virtual version of their panel that you can get at any time."
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "ai_limitations_risks",
      "name": "Limitations and Risks of AI in Qualitative Research",
      "description": "Concerns, drawbacks, and potential negative impacts associated with the adoption and reliance on AI tools in qualitative research, including issues of accuracy, nuance, trust, and broader societal implications.",
      "semantic_definition": "This code captures the critical perspectives on AI's current shortcomings and future dangers when applied to the nuanced and context-dependent nature of qualitative inquiry, as well as its wider effects.",
      "parent_id": null,
      "level": 1,
      "example_quotes": [],
      "discovery_confidence": 0.95
    },
    {
      "id": "accuracy_nuance_limitations",
      "name": "Accuracy and Nuance Limitations",
      "description": "AI's current inability to fully grasp context, subtle meanings, and the inherent nuances in qualitative data, leading to potential inaccuracies or missed insights.",
      "semantic_definition": "This code refers to the qualitative data analysis challenge where AI struggles with the subjective, contextual, and implicit aspects of human communication, often failing to capture the depth and richness that human coders can.",
      "parent_id": "ai_limitations_risks",
      "level": 2,
      "example_quotes": [
        "But I was finding that it was it was difficult for me to like a just inherently trust what it was spitting out in a way that maybe you want to just like take it and use it to draw further conclusions. And then we found when you know going back and rereading it, that there were definitely, like, nuances that were missed and things that, you know were not picked up that were relevant to our project.",
        "Especially because this project is like really politically sensitive and there's a lot of this is something that's gonna bring up as as one of the challenges when you're dealing with groups where there's like a lot of like low trust and potential for conflict and you need to be really sensitive about how you go in and sensitive about how you portray your results and what you say and how you frame things that you know, we're finding it difficult to simply just rely on what AI spits out because there's a whole lot of context around it.",
        "I used Muse once to sort sort of check we had already coded all the data and so we use it as kind of an additional check and I think I agree with what Ramya has said, like it missed anything that was nuanced. It sort of wasn't picking up on things.",
        "I say this as someone who's sort of AI naive like I I'm sure I could have programmed it better or given it better prompts. Or asked in different ways, but at that point I feel like it's faster to just do it myself, so I just feel like it's not quite doing what I want it to do and I don't know how to get it to do what I want it to.",
        "for me like having AI code, the data opens up a lot of like potential pitfalls. And I would almost could consider that like a step towards rapid qualitative analysis where you know you have to, you could look at the AI synopsis as well as read the transcripts, but there's no replacing in my mind like AI can't replace us in reading transcripts and understanding the context behind the interview in understanding the conversation.",
        "lit review - i asked an LLM for something and explicitly asked to NOT make up references, and it still made up a reference. so i need to really see good evidence that i can trust it before using for lit reviews"
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "trust_validation_concerns",
      "name": "Trust and Validation Concerns",
      "description": "The inherent skepticism and need for rigorous validation (e.g., inter-rater reliability, sub-studies) to ensure the trustworthiness and reliability of AI-generated outputs in research.",
      "semantic_definition": "This code refers to the necessity of establishing confidence in AI's analytical capabilities through empirical checks and comparisons with human performance, given the black-box nature of some AI processes.",
      "parent_id": "ai_limitations_risks",
      "level": 2,
      "example_quotes": [
        "But I was finding that it was it was difficult for me to like a just inherently trust what it was spitting out in a way that maybe you want to just like take it and use it to draw further conclusions.",
        "Especially if you're not, if you're not going, if you're you're not seeing how everything is coding, or if you're trusting some, the coding of it for parcels of the data, then you really have to trust it or Take your chances with it, I guess.",
        "I feel like you'd have to do a sub-study just like you do with any sensitivity analysis, like to look at, you know, whether it was accurate up, you know, like do some inter-rater reliability test.",
        "Yeah, just like you do with any qualitative data, if you're pulling it from multiple sources. But what? I don't usually do with like literature review people. I mean, if I have two Ra's doing qualitative data analysis, I do iterative reliability. But I don't usually do that with literature, but I would think with AI you would have to like do that. Something similar in order to use it with confidence.",
        "lit review - i asked an LLM for something and explicitly asked to NOT make up references, and it still made up a reference. so i need to really see good evidence that i can trust it before using for lit reviews"
      ],
      "discovery_confidence": 0.95
    },
    {
      "id": "red_queen_effect_race_to_bottom",
      "name": "Red Queen Effect / Race to the Bottom",
      "description": "The concern that widespread AI adoption might lead to a competitive treadmill where everyone uses AI to gain an advantage, but the net effect is merely an increase in pace without a real gain in relative position or overall benefit, potentially leading to a \"race to the bottom\" in quality or value.",
      "semantic_definition": "This code describes the phenomenon where competitive pressures force adoption of AI, leading to an arms race where increased efficiency or output by one party is immediately matched by others, resulting in no net gain for anyone, only increased effort or reduced quality.",
      "parent_id": "ai_limitations_risks",
      "level": 2,
      "example_quotes": [
        "I think somebody actually people aren't anticipating about AI development is some of this technology will be like a red Queen scenario.",
        "So you're just running faster and faster. So in the red Queen's running faster and faster to stay in the same place like on a treadmill. Right. So because your competitors start doing it. I mean, like you're saying, I'm gonna get all these more proposals submitted faster, right? But everyone else is gonna do that. And so then you're just you see what I mean? There's no actual net. Everyone stays where they are.They're just all going faster now, right?",
        "It's like one of the analogies I use that is, I think, a perfect example of this kind of technology is like self checkout in grocery stores like at the end of the day, no grocery stores have actually made any more money. From this. Right. Like they're selling the same amount of groceries, right? The the self checkout actually doesn't save money compared to paying somebody because people steal more stuff and every self checkout is more expensive than a cashier staff checkup when you add it all up they say well, if your competitors do it, you kind of have to do it. Because if Safeway does it, then customers who like that will go to Safeway. So now I'm stop and shop. Now I have to do it. See what I'm getting at?",
        "Is that is this an analogy for race to the bottom?"
      ],
      "discovery_confidence": 0.9
    },
    {
      "id": "ai_autophagy_model_collapse",
      "name": "AI Autophagy / Model Collapse",
      "description": "The theoretical risk that as AI models increasingly train on AI-generated content, they may degrade in quality, accuracy, and originality, leading to a self-referential loop of diminishing returns.",
      "semantic_definition": "This code refers to the potential long-term degradation of AI model performance and reliability due to the recursive training on synthetic data, leading to a loss of connection to real-world human-generated information.",
      "parent_id": "ai_limitations_risks",
      "level": 2,
      "example_quotes": [
        "as AI continues to create more content. And it like feeds itself and and it's basing that content on some right stuff and some wrong stuff. So it's perpetuating some wrong stuff and it just keeps getting bigger and bigger like it gets it just. It's like feeding itself. So like at some point. It's not like it might be having a heyday right now because it's based on real people's real stuff. That exist out on the Internet, but eventually AI will be like completely based on AI.",
        "I mean, the internet's already getting populated with with AI material and and you know the model developers need to vacuum all of that up to develop their super duper. Large language models, so yeah. We may. Maybe we're in a very maybe our concerns about losing our jobs are not, so maybe it'll just corrupt itself so quickly that we come back in vogue.",
        "I think isn't the theory like one theory of consciousness is that consciousness arises from like self referential loops. And so I feel like we have a lot more to worry about joy than just losing our jobs.",
        "there are a bunch of intersting articles about AI autophagy Joie",
        "It's related to Doug's point about hallucinations. I suspect the hallucinations and related problem of autophagy/model collapse are more fundamental than the AI makers are admitting."
      ],
      "discovery_confidence": 0.9
    }
  ],
  "total_codes": 13,
  "hierarchy_depth": 2,
  "discovery_method": "Thematic analysis of interview transcripts",
  "analytic_question": "What are the key themes and challenges in using AI for qualitative research?",
  "extraction_confidence": 0.9
}
{
  "codes": [
    {
      "code_name": "Causal Inference Methods",
      "description": "Techniques and methodologies used for causal inference in research.",
      "frequency": 1,
      "properties": [
        "Statistical methods",
        "Research applications"
      ],
      "dimensions": [
        "Complexity",
        "Frequency of use"
      ],
      "supporting_quotes": [],
      "confidence": 0.9,
      "parent_id": null,
      "level": 0,
      "child_codes": [
        "Common Techniques",
        "RAND Usage",
        "AI Integration"
      ]
    },
    {
      "code_name": "Common Techniques",
      "description": "Standard methods employed in causal inference research.",
      "frequency": 1,
      "properties": [
        "Breadth of techniques",
        "Evolution over time"
      ],
      "dimensions": [
        "Popularity",
        "Effectiveness"
      ],
      "supporting_quotes": [],
      "confidence": 0.85,
      "parent_id": "Causal Inference Methods",
      "level": 1,
      "child_codes": [
        "Difference-in-Difference",
        "Synthetic Control",
        "Instrumental Variables"
      ]
    },
    {
      "code_name": "RAND Usage",
      "description": "Frequency and context of causal inference methods used at RAND.",
      "frequency": 1,
      "properties": [
        "Method application",
        "Data availability"
      ],
      "dimensions": [
        "Variability",
        "Contextual factors"
      ],
      "supporting_quotes": [],
      "confidence": 0.8,
      "parent_id": "Causal Inference Methods",
      "level": 1,
      "child_codes": [
        "Method Popularity",
        "Data Dependency"
      ]
    },
    {
      "code_name": "AI Integration",
      "description": "The role and utility of AI tools in causal inference work.",
      "frequency": 1,
      "properties": [
        "Tool effectiveness",
        "Task automation"
      ],
      "dimensions": [
        "Task type",
        "User experience"
      ],
      "supporting_quotes": [],
      "confidence": 0.9,
      "parent_id": "Causal Inference Methods",
      "level": 1,
      "child_codes": [
        "AI for Coding",
        "AI for Proposal Writing",
        "AI for Literature Review"
      ]
    },
    {
      "code_name": "Challenges and Concerns",
      "description": "Barriers and apprehensions regarding AI adoption and usage.",
      "frequency": 1,
      "properties": [
        "User apprehension",
        "Institutional barriers"
      ],
      "dimensions": [
        "Perceived risks",
        "Training availability"
      ],
      "supporting_quotes": [],
      "confidence": 0.85,
      "parent_id": null,
      "level": 0,
      "child_codes": [
        "Intellectual Property Concerns",
        "Adoption Barriers",
        "Need for Training"
      ]
    },
    {
      "code_name": "Intellectual Property Concerns",
      "description": "Fears related to the misuse of intellectual property when using AI.",
      "frequency": 1,
      "properties": [
        "Ethical considerations",
        "Legal implications"
      ],
      "dimensions": [
        "Awareness",
        "Impact on usage"
      ],
      "supporting_quotes": [],
      "confidence": 0.9,
      "parent_id": "Challenges and Concerns",
      "level": 1,
      "child_codes": []
    },
    {
      "code_name": "Adoption Barriers",
      "description": "Factors hindering the widespread use of AI tools at RAND.",
      "frequency": 1,
      "properties": [
        "Cultural resistance",
        "Policy restrictions"
      ],
      "dimensions": [
        "Organizational culture",
        "Policy clarity"
      ],
      "supporting_quotes": [],
      "confidence": 0.8,
      "parent_id": "Challenges and Concerns",
      "level": 1,
      "child_codes": []
    },
    {
      "code_name": "Need for Training",
      "description": "The necessity for education and training on AI tools at RAND.",
      "frequency": 1,
      "properties": [
        "Knowledge gaps",
        "Resource availability"
      ],
      "dimensions": [
        "Training depth",
        "User engagement"
      ],
      "supporting_quotes": [],
      "confidence": 0.75,
      "parent_id": "Challenges and Concerns",
      "level": 1,
      "child_codes": []
    }
  ],
  "quotes": [
    {
      "text": "\nInterview with Kandice Kapinos, Director Methods Center for Causal Inference\n\n\n\n\nOtter? That tool is used for research. Providers and patients and they are using Otter to take notes and it transcribes and summarizes. \n\nTell me about the Methods Center on Causal Inference? Statistics is a pretty broad bucket. I am relatively new in role of Center for Causal Influence, some of the history and what it has done has evolved. Used to be under Pardee and now GER so mission changed but broadly speaking...",
      "full_text": "\nInterview with Kandice Kapinos, Director Methods Center for Causal Inference\n\n\n\n\nOtter? That tool is used for research. Providers and patients and they are using Otter to take notes and it transcribes and summarizes. \n\nTell me about the Methods Center on Causal Inference? Statistics is a pretty broad bucket. I am relatively new in role of Center for Causal Influence, some of the history and what it has done has evolved. Used to be under Pardee and now GER so mission changed but broadly speaking I view the Center as a convener of researchers who have expertise in causal inference techniques. The randomized control trial is our gold standard but they don’t happen that often, particularly in a policy evaluation setting it is more sophisticated statistical methods to get us as close as we can in our RCT design. The center has changed a bit but we host seminars and journal clubs to bring the methods to others and we are experimenting with a few things, using seed funding to help with preproposal work that is done.\n\nWhat methods are in the Quiver for causal inference? There are a few bread and butter techniques. First difference-in-difference, that literature on those techniques has evolved a lot in the last 5-10 years so advanced methods that build on that but difference-in-difference is pretty common. Synthetic control methods to get it look like an rct. Instrumental variables approach and then other techniques that fall into this bucket though less consensus to identifying causal effect. Propensity score match, interrupted timeseries analysis. Those are the big main ones; probably missing those.\n\nHow commonly are these methods used at RAND? I would say that they are pretty broad and depends on the data bc what do you have available to do an evaluation so that determines the hierarchy. Propensity score is done a ton, a question on the validity of that.  Difference in difference is used; some version of that is most frequently used.\n\nUtility of AI for causal inference work? … I can tell you a bit hos… I just went last week to the American society for health economists and heard lots of researchers that are using the subscription based ai products. I think there is more use than just what I know. \n\nI have used AI tools to help with my code.  I know in general how to execute one of these methods but sometime there are new packages written but my code is having errors so I can take the code and put it in an LLM; can you fix this error or can you write this more concisely? \n\nI’ve also done things for proposal writing and taken my idea where I want to use a particular design and poke holes in this; What are the problems with this; how can I strengthen this?   like I can take the abstract I’ve written up and I want to study this policy that was implemented on impacts of y variable and I am going to use this synthetic control method, tell me what I’m missing or how… I’ve used the RAND Chat and I’ve used Claude.\n\n[This use is] mostly variation of LLMs but it may be ignorant of what is being used.  \n\nWhat are your thoughts about Claude and the RAND LLM? The RAND one I used early on and used it to do tedious things and playing with code and I found someone else’s code and asked can you convert this R code to Stata code and kept playing with it and learned what is good and not good. My husband was using Claude and told me it is good at writing things. So can it tell me if this is a valid design.  Also, sometimes to re-write or shorten things but not exactly causal inference but to make things shorter. I would take “Reddit explain like I’m 5”. Esp with methods, hard for ppl who are not experts to understand. So I take the text and say explain like I’m five. The other thing I’ve done; I’ve taken text and said which of the sentences in here will upset some opposed to DEI and it will flag sentences and makes me look at it again.\n\nOther ways you use? Not a good representative sample, I’ve increased my use the past 6 months but I’ve been writing proposals non-stop.  How helpful are LLM’s for proposals. I take the whole proposal and say write an executive summary; it is great at doing that; you can’t trust it but sometimes stuff that is off and misses nuance but it is pretty good at that. I’ve played a little with telling it to, to make an image for proposal. Somewhere you can say, I want something that looks like an experiment but relevant to labor markets.\n\nHow do others use AI? The other thing that I did was a year ago now and not a causal inference, but we did write a python script to use the RAND CHAT to review a bunch of papers. So we did the literature review and had it spit out in a spreadsheet a once sentence summary of the paper or we asked it questions, is this paper based in the US? It was not great at this. Also, what is the sample of this paper, x, adults between ages of 18 and 45. so we had it put it in an excel file and so used it to winnow down a set of papers… it was pretty good. The main reason we did that was because the client a federal agency wanted us to do this massive literature review in one month.  So we … we had a librarian gave us the initial list, it was originally 5,000 papers and removed duplicates down to 3500 that it went through. \n\nHow do you see adoption of AI at RAND? Most ppl I ask, at RAND there are not as many ppl using it; the few that have say they use it to do what I am doing to help fix code or wordsmith text.\n\nFor the causal inference research, what aspects are the most time consuming?   When I think about it, it is not going to necessarily help you figure out what you need to do. The researcher has honed that overtime so not easily replicating it. But the time-consuming process of pulling data down, checking code. So one thing when I feed it in and there is an error, but then you can use the ai tools to check the code, annotate the code, replicability those are time consuming and for AI.  As opposed to thinking through the logic of the science and thinking is it credible, that is harder (for ai). Not necessarily more time consuming but harder to outsource to an ai tool.\n\nAI Useful for pulling data?  Even if you are collecting the data yourself and I was a study that was a trial and we were using survey. We had to go and get it and clean and prepare it for use and check that there are not errors. Could be taking publicly available datasets, a lot of the federal, some federal agencies are using the Api where you can tell it each time you run your code, go to this external website and pull data down fresh in case there is updating to that. Sometimes you want to do tha…. You could write code to pull it down.  The thing is, not all data is saved the same way, some use SQL, a lot of public use data like claims, those are massive datasets so you don’t want to pull down the entire dataset.\n\nAre there specialized AI programs for coding?  That is a good question I am not sure. I have not been using any specialized.\n\nCan you tell me more about adoption of AI at RAND? I think based on the professional conference I went to, I think we might be a little bit slower [level of adoption], whether that is right I don’t know. I personally feel others are using this and I should… it is speeding things up for ppl in a way that makes me feel I don’t want to be left behind but I feel a little about it.\n\nAnything about using AI at RAND that makes you nervous? The code part I am not nervous at all, who cares if somebody takes my code and reuses it. Some of the other stuff, I don’t want to inadvertently take someone else’s intellectual property. Saw a thing on john Oliver, ppl making images, based on what is in the public and making something new so it is kind of stealing. I don’t want to take anyone’s intellectual property.  But a code is code so that not an issue. But if I were to take my proposal and say write this, is it going to take texts from others? ….\n\nOther concerns? I think there are really good use case, tools related to literature reviews, environmental scans, that is really good. I think the RAND CHAT one is not as good, a couple of times I would ask RAND CHAT, are there systematic studies on blah or what do you know about x and y and it would give me papers/citations that were not real. So I always check. And Claude, what do we know about this and it gave me a bunch of links to the articles so I could check it unless you say give me the cite.\n\nWhat are the barriers to adoption at RAND?  To be honest I am not sure, I don’t know if ppl feel like they are not supposed to use these bc I know RAND has its own specific rand chat and rand came out and said don’t use something, so part of me wonders if ppl are hesitant for that reason. I guess if you are coding work that classified.  \n\nIs there a need for Training/education on AI at RAND? There could be more along those lines, showcasing how ppl use it successfully. A little bit but not a ton and someone super savvy and using it a lot could give a rundown of how they use it day to day. I told several ppl how I use it to check my proposals and esp. this year with changes in funding.   Ppl are surprised?  Like asking LLM about getting DEI flagged?  I don’t think ppl are doing that at rand and I’m not sure why bc we have the rand chat.\n\nHaving ppl using it and sharing. I have a sister who is an attorney and she uses it in ways I would not think of. They track legislation and they are getting summaries or tracking how we spend their time.  \n\nWho else? I don’t know… maybe we can create something for sharing.\n\nOther Project management uses? There was another group of ppl interviewing about ai tools. I said I thought it was odd we don’t use some of the internal budgeting and figuring out where ppl have labor allocated to do labor forecasting. Thinking about how we already have a lot of data there and how we can pull it… to staff projects I’m bidding.  I’m sure there are other project management tasks. My experience is that the PH.D. level ppl are less great about management so they may have not as much incite, they have right hand man/woman and they \n\n",
      "speaker": "Interview Kandice Kapinos",
      "filename": "Interview Kandice Kapinos.docx",
      "codes": []
    }
  ],
  "relationships": [
    {
      "central_category": "Causal Inference Methods",
      "related_category": "Common Techniques",
      "relationship_type": "contextual",
      "conditions": [
        "Statistical methods available",
        "Research applications"
      ],
      "consequences": [
        "Broad understanding of causal inference",
        "Evolution of techniques over time"
      ],
      "strength": 0.85
    },
    {
      "central_category": "AI Integration",
      "related_category": "Challenges and Concerns",
      "relationship_type": "intervening",
      "conditions": [
        "User apprehension about AI",
        "Institutional barriers to AI adoption"
      ],
      "consequences": [
        "Hesitance in using AI tools",
        "Potential underutilization of AI capabilities"
      ],
      "strength": 0.85
    },
    {
      "central_category": "AI Integration",
      "related_category": "Need for Training",
      "relationship_type": "causal",
      "conditions": [
        "Knowledge gaps in AI usage",
        "Resource availability for training"
      ],
      "consequences": [
        "Increased proficiency in AI tools",
        "Enhanced productivity in research tasks"
      ],
      "strength": 0.75
    },
    {
      "central_category": "Adoption Barriers",
      "related_category": "Intellectual Property Concerns",
      "relationship_type": "contextual",
      "conditions": [
        "Cultural resistance to AI tools",
        "Policy restrictions on AI usage"
      ],
      "consequences": [
        "Reduced innovation in research methods",
        "Increased caution in AI tool adoption"
      ],
      "strength": 0.8
    },
    {
      "central_category": "Challenges and Concerns",
      "related_category": "AI Integration",
      "relationship_type": "intervening",
      "conditions": [
        "User apprehension about AI",
        "Perceived limitations of AI tools"
      ],
      "consequences": [
        "Limited exploration of AI capabilities",
        "Potential for missed opportunities in research"
      ],
      "strength": 0.8
    }
  ],
  "core_categories": [
    {
      "category_name": "AI Integration in Causal Inference",
      "description": "",
      "properties": [],
      "related_codes": []
    }
  ],
  "metadata": {
    "total_interviews": 1,
    "total_codes": 8,
    "total_relationships": 5,
    "total_core_categories": 1,
    "analysis_timestamp": "2025-09-09T03:38:06.943360",
    "methodology": "grounded_theory"
  }
}
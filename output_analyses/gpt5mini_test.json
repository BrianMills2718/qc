{
  "completed_at": "2026-02-10T18:48:07.445784",
  "config": {},
  "created_at": "2026-02-10T18:44:01.462268",
  "id": "job_20260210_184401",
  "interviews_count": 1,
  "results": {
    "analysis_summary": "Analyzed 1 interviews using structured qualitative coding",
    "codes_identified": [
      {
        "code": "Methods Center Role",
        "confidence": 0.95,
        "frequency": 4
      },
      {
        "code": "Center Functions and Activities",
        "confidence": 0.9,
        "frequency": 2
      },
      {
        "code": "History and Organizational Structure",
        "confidence": 0.85,
        "frequency": 4
      },
      {
        "code": "Causal Inference Methods",
        "confidence": 0.98,
        "frequency": 4
      },
      {
        "code": "Commonly Used Techniques",
        "confidence": 0.95,
        "frequency": 4
      },
      {
        "code": "Method Selection and Data Constraints",
        "confidence": 0.9,
        "frequency": 4
      },
      {
        "code": "AI Use Cases",
        "confidence": 0.98,
        "frequency": 4
      },
      {
        "code": "Code Debugging and Translation",
        "confidence": 0.97,
        "frequency": 4
      },
      {
        "code": "Code Refactoring and Annotation",
        "confidence": 0.92,
        "frequency": 4
      },
      {
        "code": "Proposal Writing and Editing",
        "confidence": 0.96,
        "frequency": 4
      },
      {
        "code": "Automating Literature Reviews",
        "confidence": 0.94,
        "frequency": 4
      },
      {
        "code": "Explainability and Text Simplification",
        "confidence": 0.93,
        "frequency": 4
      },
      {
        "code": "Visuals / Image Generation",
        "confidence": 0.8,
        "frequency": 2
      },
      {
        "code": "Specific AI Tools",
        "confidence": 0.97,
        "frequency": 4
      },
      {
        "code": "RAND Chat Experience",
        "confidence": 0.9,
        "frequency": 4
      },
      {
        "code": "Claude Experience",
        "confidence": 0.9,
        "frequency": 4
      },
      {
        "code": "Subscription-based AI Products",
        "confidence": 0.75,
        "frequency": 4
      },
      {
        "code": "Data and Workflow Tasks",
        "confidence": 0.96,
        "frequency": 4
      },
      {
        "code": "Automating Data Retrieval",
        "confidence": 0.9,
        "frequency": 4
      },
      {
        "code": "Cleaning and Preparing Data",
        "confidence": 0.96,
        "frequency": 4
      },
      {
        "code": "Reproducibility and Code Management",
        "confidence": 0.9,
        "frequency": 4
      },
      {
        "code": "Perceived Benefits and Limitations",
        "confidence": 0.97,
        "frequency": 4
      },
      {
        "code": "Time Savings and Productivity Gains",
        "confidence": 0.95,
        "frequency": 4
      },
      {
        "code": "Limits on Deep Scientific Judgment",
        "confidence": 0.97,
        "frequency": 4
      },
      {
        "code": "Hallucination and Reliability Issues",
        "confidence": 0.96,
        "frequency": 4
      },
      {
        "code": "Adoption, Barriers, and Training Needs",
        "confidence": 0.95,
        "frequency": 4
      },
      {
        "code": "Current Adoption Patterns",
        "confidence": 0.88,
        "frequency": 4
      },
      {
        "code": "Policy, Guidance, and Hesitancy",
        "confidence": 0.9,
        "frequency": 4
      },
      {
        "code": "Training and Peer Sharing Needs",
        "confidence": 0.9,
        "frequency": 4
      },
      {
        "code": "Ethics, IP, and Attribution Concerns",
        "confidence": 0.96,
        "frequency": 4
      },
      {
        "code": "Distinction Between Code and Other IP",
        "confidence": 0.9,
        "frequency": 2
      },
      {
        "code": "Citation Accuracy and Fabricated References",
        "confidence": 0.97,
        "frequency": 4
      },
      {
        "code": "Project Management and Administrative Uses",
        "confidence": 0.88,
        "frequency": 4
      },
      {
        "code": "Resource Allocation and Forecasting",
        "confidence": 0.8,
        "frequency": 4
      },
      {
        "code": "Administrative Task Automation",
        "confidence": 0.75,
        "frequency": 4
      }
    ],
    "demo_mode": false,
    "full_analysis": "=== COMPREHENSIVE QUALITATIVE CODING ANALYSIS ===\n\nPHASE 1: HIERARCHICAL CODE DISCOVERY\n{\n  \"codes\": [\n    {\n      \"id\": \"METHODS_CENTER\",\n      \"name\": \"Methods Center Role\",\n      \"description\": \"Describes the purpose, history, and functions of the Methods Center for Causal Inference as explained by the interviewee. Covers how the center convenes researchers, hosts seminars and journal clubs, and provides seed funding for pre-proposal work. Highlights evolving mission and place within institutional structure.\",\n      \"semantic_definition\": \"Any statement about the center's mission, organizational changes, activities (seminars, journal clubs), convening role, or funding/support functions.\",\n      \"parent_id\": null,\n      \"level\": 0,\n      \"example_quotes\": [\n        \"I view the Center as a convener of researchers who have expertise in causal inference techniques.\",\n        \"We host seminars and journal clubs to bring the methods to others and we are experimenting with a few things, using seed funding to help with preproposal work that is done.\"\n      ],\n      \"discovery_confidence\": 0.95\n    },\n    {\n      \"id\": \"METHODS_CENTER_FUNCTIONS\",\n      \"name\": \"Center Functions and Activities\",\n      \"description\": \"Specific activities and operational practices of the Methods Center, including hosting seminars, journal clubs, experimenting with seed funding, and supporting early-stage proposal work. Emphasizes the center's role in knowledge dissemination and methodological collaboration.\",\n      \"semantic_definition\": \"References to concrete center activities (seminars, journal clubs, seed funding, convening researchers) or examples of support it provides.\",\n      \"parent_id\": \"METHODS_CENTER\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"We host seminars and journal clubs to bring the methods to others and we are experimenting with a few things, using seed funding to help with preproposal work that is done.\"\n      ],\n      \"discovery_confidence\": 0.9\n    },\n    {\n      \"id\": \"METHODS_CENTER_HISTORY_AND_STRUCTURE\",\n      \"name\": \"History and Organizational Structure\",\n      \"description\": \"Mentions historical placement and changes in organizational structure and mission (e.g., reporting lines) as well as how that has influenced the center's focus. Captures comments about evolving mission and administrative shifts.\",\n      \"semantic_definition\": \"Any mention of the center's history, prior organizational alignment, mission changes, or reporting structure.\",\n      \"parent_id\": \"METHODS_CENTER\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"The center has changed a bit but we host seminars and journal clubs...\",\n        \"Used to be under Pardee and now GER so mission changed...\"\n      ],\n      \"discovery_confidence\": 0.85\n    },\n    {\n      \"id\": \"CAUSAL_METHODS\",\n      \"name\": \"Causal Inference Methods\",\n      \"description\": \"Describes the suite of causal inference techniques commonly used by researchers, especially in policy evaluation contexts. Discusses the 'gold standard' of RCTs, and the range of observational or quasi-experimental methods used when RCTs are not feasible.\",\n      \"semantic_definition\": \"Any discussion of causal inference methods, their relative place (e.g., RCT as gold standard), or how methods are chosen and applied in practice.\",\n      \"parent_id\": null,\n      \"level\": 0,\n      \"example_quotes\": [\n        \"The randomized control trial is our gold standard but they don’t happen that often...\",\n        \"Difference-in-difference, synthetic control methods, instrumental variables approach... propensity score match, interrupted time series analysis.\"\n      ],\n      \"discovery_confidence\": 0.98\n    },\n    {\n      \"id\": \"CAUSAL_COMMON_METHODS\",\n      \"name\": \"Commonly Used Techniques\",\n      \"description\": \"Lists and characterizes the primary causal inference techniques the interviewee mentioned, including difference-in-differences, synthetic control, instrumental variables, propensity scores, and interrupted time series. Notes that some methods have more consensus and frequency of use than others.\",\n      \"semantic_definition\": \"Statements enumerating or describing specific causal methods researchers use and their relative prevalence or maturity.\",\n      \"parent_id\": \"CAUSAL_METHODS\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"Difference-in-difference is pretty common. Synthetic control methods to get it look like an rct. Instrumental variables approach...\",\n        \"Propensity score is done a ton, a question on the validity of that.\"\n      ],\n      \"discovery_confidence\": 0.95\n    },\n    {\n      \"id\": \"CAUSAL_METHODS_SELECTION_AND_LIMITATIONS\",\n      \"name\": \"Method Selection and Data Constraints\",\n      \"description\": \"Explains that choice of causal method is often driven by available data and the evaluation context, and that some methods have questions around validity. Highlights practical constraints that shape analytic choices.\",\n      \"semantic_definition\": \"Any text about how data availability, evaluation design, or validity concerns determine which causal method is used.\",\n      \"parent_id\": \"CAUSAL_METHODS\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"Depends on the data bc what do you have available to do an evaluation so that determines the hierarchy.\",\n        \"Some version of difference-in-difference is most frequently used.\"\n      ],\n      \"discovery_confidence\": 0.9\n    },\n    {\n      \"id\": \"AI_USAGE\",\n      \"name\": \"AI Use Cases\",\n      \"description\": \"Covers the concrete ways the interviewee and colleagues use AI/LLMs in their research and daily work. Includes coding assistance, proposal writing, literature review automation, text simplification, DEI flagging, and image generation for proposals.\",\n      \"semantic_definition\": \"Any described practical application of AI tools, including examples of tasks performed, workflows augmented, or specific outputs produced by AI.\",\n      \"parent_id\": null,\n      \"level\": 0,\n      \"example_quotes\": [\n        \"I have used AI tools to help with my code.\",\n        \"I take the whole proposal and say write an executive summary; it is great at doing that.\"\n      ],\n      \"discovery_confidence\": 0.98\n    },\n    {\n      \"id\": \"AI_CODE_HELP\",\n      \"name\": \"Code Debugging and Translation\",\n      \"description\": \"Use of LLMs to debug code, translate code between languages (e.g., R to Stata), make code more concise, and annotate or check code for reproducibility. Emphasizes iterative use to fix errors and learn from examples.\",\n      \"semantic_definition\": \"Any instance where AI is used to fix code errors, refactor or translate code, annotate scripts, or assist with reproducibility-related code tasks.\",\n      \"parent_id\": \"AI_USAGE\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"I can take the code and put it in an LLM; can you fix this error or can you write this more concisely?\",\n        \"I asked can you convert this R code to Stata code and kept playing with it and learned what is good and not good.\"\n      ],\n      \"discovery_confidence\": 0.97\n    },\n    {\n      \"id\": \"AI_CODE_REFACTORING\",\n      \"name\": \"Code Refactoring and Annotation\",\n      \"description\": \"A specific, detailed code assistance use where AI rewrites, shortens, or annotates code to improve clarity and replicability. Often used for learning new packages or resolving idiosyncratic errors.\",\n      \"semantic_definition\": \"Use cases in which AI rewrites code for concision, annotates code for clarity, or helps adapt code to different environments/libraries.\",\n      \"parent_id\": \"AI_CODE_HELP\",\n      \"level\": 2,\n      \"example_quotes\": [\n        \"Can you write this more concisely?\",\n        \"I found someone else’s code and asked can you convert this R code to Stata code...\"\n      ],\n      \"discovery_confidence\": 0.92\n    },\n    {\n      \"id\": \"AI_PROPOSAL_SUPPORT\",\n      \"name\": \"Proposal Writing and Editing\",\n      \"description\": \"Use of AI to draft, summarize, shorten, or critique proposal text including generating executive summaries and suggesting design improvements. The interviewee uses AI to 'poke holes' in proposed designs and refine abstracts.\",\n      \"semantic_definition\": \"Any described use of AI to create, edit, summarize, or critique proposals, abstracts, and funding text.\",\n      \"parent_id\": \"AI_USAGE\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"I've done things for proposal writing and taken my idea ... poke holes in this; What are the problems with this; how can I strengthen this?\",\n        \"I take the whole proposal and say write an executive summary; it is great at doing that; you can’t trust it but sometimes stuff that is off and misses nuance.\"\n      ],\n      \"discovery_confidence\": 0.96\n    },\n    {\n      \"id\": \"AI_LITERATURE_REVIEW\",\n      \"name\": \"Automating Literature Reviews\",\n      \"description\": \"Using AI to process large literature sets, generate one-sentence summaries, extract metadata (like sample characteristics or country), and assist in winnowing papers for faster review. This was applied to thousands of papers to meet tight deadlines.\",\n      \"semantic_definition\": \"Instances where AI extracts summaries, metadata, or classifications from academic papers to expedite literature reviews and screening.\",\n      \"parent_id\": \"AI_USAGE\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"We did the literature review and had it spit out in a spreadsheet a one sentence summary of the paper ... it was pretty good.\",\n        \"The client ... wanted us to do this massive literature review in one month. ... it went through [3500 papers].\"\n      ],\n      \"discovery_confidence\": 0.94\n    },\n    {\n      \"id\": \"AI_COMMUNICATION_SIMPLIFICATION\",\n      \"name\": \"Explainability and Text Simplification\",\n      \"description\": \"Use of AI to simplify technical text (e.g., 'explain like I'm five') and to flag potentially sensitive language (e.g., DEI flags). Helps non-experts understand methods and refines wording for broader audiences.\",\n      \"semantic_definition\": \"Any use of AI to simplify, rephrase, or evaluate text for accessibility, tone, or potential sensitivity.\",\n      \"parent_id\": \"AI_USAGE\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"So I take the text and say explain like I’m five.\",\n        \"I would take the text and say which of the sentences in here will upset some opposed to DEI and it will flag sentences.\"\n      ],\n      \"discovery_confidence\": 0.93\n    },\n    {\n      \"id\": \"AI_IMAGE_SUPPORT\",\n      \"name\": \"Visuals / Image Generation\",\n      \"description\": \"Using AI tools to create images for proposals or presentations, sometimes requesting visuals that conceptually represent experimental designs or labor market relevance. Treated as an auxiliary creative aid.\",\n      \"semantic_definition\": \"References to generating or asking AI to create images or visual representations for proposals or communication materials.\",\n      \"parent_id\": \"AI_USAGE\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"I've played a little with telling it to, to make an image for proposal. ... I want something that looks like an experiment but relevant to labor markets.\"\n      ],\n      \"discovery_confidence\": 0.8\n    },\n    {\n      \"id\": \"AI_TOOLS\",\n      \"name\": \"Specific AI Tools\",\n      \"description\": \"Mentions of particular AI platforms or products used by the interviewee or colleagues, including RAND Chat, Claude, and subscription-based AI services. Notes strengths, weaknesses, and typical tasks performed with each tool.\",\n      \"semantic_definition\": \"Any explicit reference to named AI tools, platforms, or subscriptions and comments about their capabilities or observed behaviors.\",\n      \"parent_id\": null,\n      \"level\": 0,\n      \"example_quotes\": [\n        \"I’ve used the RAND Chat and I’ve used Claude.\",\n        \"I just went last week to the American society for health economists and heard lots of researchers that are using the subscription based ai products.\"\n      ],\n      \"discovery_confidence\": 0.97\n    },\n    {\n      \"id\": \"TOOL_RAND_CHAT\",\n      \"name\": \"RAND Chat Experience\",\n      \"description\": \"Descriptions of experiences using RAND's internal LLM (RAND Chat), including tasks it handled well (tedious code tasks) and limitations (inaccurate citations). The interviewee used it early on for code tasks and for quick queries but noted reliability issues.\",\n      \"semantic_definition\": \"Statements about experiences, strengths, and limitations specifically associated with RAND Chat.\",\n      \"parent_id\": \"AI_TOOLS\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"The RAND one I used early on and used it to do tedious things and playing with code...\",\n        \"The RAND CHAT one is not as good, a couple of times I would ask RAND CHAT ... and it would give me papers/citations that were not real.\"\n      ],\n      \"discovery_confidence\": 0.9\n    },\n    {\n      \"id\": \"TOOL_CLAUDE\",\n      \"name\": \"Claude Experience\",\n      \"description\": \"Mentions use of the Claude LLM for writing tasks and general text generation. The interviewee and family members used Claude and found it good at writing and summarization tasks.\",\n      \"semantic_definition\": \"Any commentary specifically about experiences with the Claude AI platform and its perceived strengths.\",\n      \"parent_id\": \"AI_TOOLS\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"My husband was using Claude and told me it is good at writing things.\",\n        \"Also, Claude, what do we know about this and it gave me a bunch of links to the articles so I could check it unless you say give me the cite.\"\n      ],\n      \"discovery_confidence\": 0.9\n    },\n    {\n      \"id\": \"TOOL_SUBSCRIPTION_AI\",\n      \"name\": \"Subscription-based AI Products\",\n      \"description\": \"General observation that many researchers use commercial, subscription AI products, especially observed at conferences. These products are used beyond what the interviewee personally knows and may accelerate certain tasks.\",\n      \"semantic_definition\": \"References to commercial/subscription AI products used by peers or observed in the field rather than internal tools.\",\n      \"parent_id\": \"AI_TOOLS\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"I heard lots of researchers that are using the subscription based ai products.\",\n        \"I think there is more use than just what I know.\"\n      ],\n      \"discovery_confidence\": 0.75\n    },\n    {\n      \"id\": \"DATA_WORKFLOWS\",\n      \"name\": \"Data and Workflow Tasks\",\n      \"description\": \"Concerns and practices related to pulling, cleaning, preparing, and automating data retrieval for analysis. Discusses large datasets, APIs, different storage formats (SQL), and the time-consuming nature of these tasks.\",\n      \"semantic_definition\": \"Any comments about data acquisition, formats, cleaning, automation of pulls, or challenges managing large or public datasets.\",\n      \"parent_id\": null,\n      \"level\": 0,\n      \"example_quotes\": [\n        \"The time-consuming process of pulling data down, checking code.\",\n        \"Some federal agencies are using the Api where you can tell it each time you run your code, go to this external website and pull data down fresh...\"\n      ],\n      \"discovery_confidence\": 0.96\n    },\n    {\n      \"id\": \"DATA_PULLING_AUTOMATION\",\n      \"name\": \"Automating Data Retrieval\",\n      \"description\": \"Use of scripts or AI-assisted code to automatically pull updated datasets from APIs or external sources. Notes differences in data storage systems and tradeoffs of pulling large datasets versus targeted subsets.\",\n      \"semantic_definition\": \"References to writing code or using automation to fetch data programmatically (APIs, external websites) and considerations around dataset size/format.\",\n      \"parent_id\": \"DATA_WORKFLOWS\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"Some federal agencies are using the Api where you can tell it each time you run your code, go to this external website and pull data down fresh in case there is updating to that.\",\n        \"A lot of public use data like claims, those are massive datasets so you don’t want to pull down the entire dataset.\"\n      ],\n      \"discovery_confidence\": 0.9\n    },\n    {\n      \"id\": \"DATA_CLEANING_AND_PREPARATION\",\n      \"name\": \"Cleaning and Preparing Data\",\n      \"description\": \"Tasks related to cleaning survey or trial data, preparing datasets for analysis, and checking for errors. The interviewee emphasized these as time-consuming, often requiring careful manual inspection and code verification.\",\n      \"semantic_definition\": \"Any mention of cleaning, preparing, validating, or checking data prior to analysis, including handling survey or trial data.\",\n      \"parent_id\": \"DATA_WORKFLOWS\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"We had to go and get it and clean and prepare it for use and check that there are not errors.\",\n        \"The time-consuming process of pulling data down, checking code. So one thing when I feed it in and there is an error...\"\n      ],\n      \"discovery_confidence\": 0.96\n    },\n    {\n      \"id\": \"REPRODUCIBILITY_AND_CODE_SHARING\",\n      \"name\": \"Reproducibility and Code Management\",\n      \"description\": \"Discussion of annotating code, checking reproducibility, and the role AI can play in supporting these tasks. Emphasizes that AI can help with tedious verification but that scientific logic remains a human task.\",\n      \"semantic_definition\": \"Statements about reproducibility practices (annotating code, checking outputs), code sharing, and AI's potential to support these processes.\",\n      \"parent_id\": \"DATA_WORKFLOWS\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"You can use the ai tools to check the code, annotate the code, replicability those are time consuming and for AI.\",\n        \"But the time-consuming process of pulling data down, checking code.\"\n      ],\n      \"discovery_confidence\": 0.9\n    },\n    {\n      \"id\": \"BENEFITS_LIMITATIONS_OF_AI\",\n      \"name\": \"Perceived Benefits and Limitations\",\n      \"description\": \"Covers interviewee views on what AI does well (speeding up tedious tasks, summarization, code fixes) and where it falls short (conceptual reasoning, trustworthiness, nuance). Distinguishes time saved from tasks that cannot be outsourced.\",\n      \"semantic_definition\": \"Any evaluation of AI's strengths and weaknesses for research tasks, including where it helps and where it cannot replace human judgement.\",\n      \"parent_id\": null,\n      \"level\": 0,\n      \"example_quotes\": [\n        \"It is speeding things up for ppl in a way that makes me feel I don’t want to be left behind but I feel a little about it.\",\n        \"It is not going to necessarily help you figure out what you need to do... thinking through the logic of the science ... is harder (for ai).\"\n      ],\n      \"discovery_confidence\": 0.97\n    },\n    {\n      \"id\": \"AI_TIME_SAVINGS\",\n      \"name\": \"Time Savings and Productivity Gains\",\n      \"description\": \"AI reduces time on repetitive or tedious tasks such as summarizing literature, drafting executive summaries, debugging code, and producing quick edits. These gains are cited as the main practical benefit motivating adoption.\",\n      \"semantic_definition\": \"Any claim or example that AI speeds up work, reduces manual effort, or increases productivity on mundane tasks.\",\n      \"parent_id\": \"BENEFITS_LIMITATIONS_OF_AI\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"It is speeding things up for ppl ... I’ve increased my use the past 6 months but I’ve been writing proposals non-stop.\",\n        \"It was pretty good ... we had it put it in an excel file and so used it to winnow down a set of papers.\"\n      ],\n      \"discovery_confidence\": 0.95\n    },\n    {\n      \"id\": \"AI_LIMITS_ON_CONCEPTUAL_WORK\",\n      \"name\": \"Limits on Deep Scientific Judgment\",\n      \"description\": \"AI is seen as limited in formulating research strategy, determining what analyses are needed, and evaluating the credibility of scientific designs. The interviewee emphasized the difficulty in outsourcing the conceptual logic of science.\",\n      \"semantic_definition\": \"Statements describing AI's insufficiency for high-level conceptual reasoning, research design choices, or credibility assessments.\",\n      \"parent_id\": \"BENEFITS_LIMITATIONS_OF_AI\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"It is not going to necessarily help you figure out what you need to do. The researcher has honed that overtime so not easily replicating it.\",\n        \"Thinking through the logic of the science and thinking is it credible, that is harder (for ai).\"\n      ],\n      \"discovery_confidence\": 0.97\n    },\n    {\n      \"id\": \"AI_ERROR_AND_HALLUCINATION_RISK\",\n      \"name\": \"Hallucination and Reliability Issues\",\n      \"description\": \"Concerns about AI producing incorrect outputs, false citations, or misleading summaries. The interviewee reported checking AI-provided citations and experiencing instances where RAND Chat returned non-real papers.\",\n      \"semantic_definition\": \"Any mention of AI hallucinating facts, producing inaccurate citations, or otherwise producing outputs that require verification.\",\n      \"parent_id\": \"BENEFITS_LIMITATIONS_OF_AI\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"RAND CHAT ... would give me papers/citations that were not real. So I always check.\",\n        \"It will give me a bunch of links to the articles so I could check it unless you say give me the cite.\"\n      ],\n      \"discovery_confidence\": 0.96\n    },\n    {\n      \"id\": \"ADOPTION_AND_TRAINING\",\n      \"name\": \"Adoption, Barriers, and Training Needs\",\n      \"description\": \"Covers how widely AI is used at RAND, perceived hesitancy due to policy or familiarity, and the desire for more training and showcases about everyday use cases. Includes suggestions for peer sharing and demonstrations by savvy users.\",\n      \"semantic_definition\": \"Any statements about current adoption levels, reasons people may not use AI (policy, hesitancy), needs for training, or recommended dissemination of use cases.\",\n      \"parent_id\": null,\n      \"level\": 0,\n      \"example_quotes\": [\n        \"Most ppl I ask, at RAND there are not as many ppl using it; the few that have say they use it to do what I am doing.\",\n        \"There could be more along those lines, showcasing how ppl use it successfully.\"\n      ],\n      \"discovery_confidence\": 0.95\n    },\n    {\n      \"id\": \"ADOPTION_LEVEL\",\n      \"name\": \"Current Adoption Patterns\",\n      \"description\": \"Observations about limited but growing adoption among RAND staff, with more uptake among a subset who use it for code and text tasks. The interviewee perceives others using subscription products beyond RAND's internal tool.\",\n      \"semantic_definition\": \"Descriptions of who is using AI at RAND, frequency of use, and whether adoption is widespread or limited.\",\n      \"parent_id\": \"ADOPTION_AND_TRAINING\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"Most ppl I ask, at RAND there are not as many ppl using it; the few that have say they use it to do what I am doing to help fix code or wordsmith text.\",\n        \"I personally feel others are using this and I should… it is speeding things up for ppl...\"\n      ],\n      \"discovery_confidence\": 0.88\n    },\n    {\n      \"id\": \"POLICY_AND_RESTRICTION_IMPACT\",\n      \"name\": \"Policy, Guidance, and Hesitancy\",\n      \"description\": \"Notes that organizational policies or guidance (e.g., warnings about tool use) may deter staff from using external AI tools, and the potential for classified/regulated work to restrict AI use. Suggests uncertainty about permissible use.\",\n      \"semantic_definition\": \"Any statements linking organizational policy, guidance, or data classification to hesitancy or restrictions on AI use.\",\n      \"parent_id\": \"ADOPTION_AND_TRAINING\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"I know RAND has its own specific rand chat and rand came out and said don’t use something, so part of me wonders if ppl are hesitant for that reason.\",\n        \"I guess if you are coding work that classified.\"\n      ],\n      \"discovery_confidence\": 0.9\n    },\n    {\n      \"id\": \"TRAINING_AND_SHOWCASING\",\n      \"name\": \"Training and Peer Sharing Needs\",\n      \"description\": \"Calls for more demonstrations and practical training where experienced users show day-to-day workflows. Interviewee suggested short showcases from savvy users to demonstrate successful use cases (e.g., checking proposals, DEI flagging).\",\n      \"semantic_definition\": \"Any expression of need for formal or informal training, demonstrations, or sharing of best practices among staff.\",\n      \"parent_id\": \"ADOPTION_AND_TRAINING\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"There could be more along those lines, showcasing how ppl use it successfully. A little bit but not a ton and someone super savvy ... could give a rundown of how they use it day to day.\",\n        \"Having ppl using it and sharing. I have a sister who is an attorney and she uses it in ways I would not think of.\"\n      ],\n      \"discovery_confidence\": 0.9\n    },\n    {\n      \"id\": \"ETHICS_AND_IP\",\n      \"name\": \"Ethics, IP, and Attribution Concerns\",\n      \"description\": \"Concerns about intellectual property, originality of AI-generated content, and ethical use of public works for generating new outputs. Interviewee differentiates tolerance for code reuse from worry about plagiarized text or images.\",\n      \"semantic_definition\": \"Any statements about intellectual property risks, concerns that AI may 'steal' or improperly reuse copyrighted content, or worries about attribution.\",\n      \"parent_id\": null,\n      \"level\": 0,\n      \"example_quotes\": [\n        \"I don’t want to inadvertently take someone else’s intellectual property.\",\n        \"Saw a thing on john Oliver, ppl making images, based on what is in the public and making something new so it is kind of stealing.\"\n      ],\n      \"discovery_confidence\": 0.96\n    },\n    {\n      \"id\": \"IP_CONCERNS_CODE_VS_TEXT\",\n      \"name\": \"Distinction Between Code and Other IP\",\n      \"description\": \"Interviewee felt code reuse is less concerning than reuse of written text or images, and is comfortable with others using code. However, she expressed concern about prose or imagery being derived from others' IP without attribution.\",\n      \"semantic_definition\": \"Statements differentiating perceived acceptable reuse of code from problematic reuse of written materials or images produced by AI.\",\n      \"parent_id\": \"ETHICS_AND_IP\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"The code part I am not nervous at all, who cares if somebody takes my code and reuses it. ... But if I were to take my proposal and say write this, is it going to take texts from others?\"\n      ],\n      \"discovery_confidence\": 0.9\n    },\n    {\n      \"id\": \"CITATION_AND_HALLUCINATION_CONCERNS\",\n      \"name\": \"Citation Accuracy and Fabricated References\",\n      \"description\": \"Specific concern about AI providing inaccurate or fabricated citations and links, requiring human verification. Interviewee recounted encountering non-real papers and needing to check AI outputs.\",\n      \"semantic_definition\": \"Any mention of AI producing false references, invented papers, or unreliable citations that necessitate verification.\",\n      \"parent_id\": \"ETHICS_AND_IP\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"RAND CHAT ... would give me papers/citations that were not real. So I always check.\",\n        \"Claude ... it gave me a bunch of links to the articles so I could check it unless you say give me the cite.\"\n      ],\n      \"discovery_confidence\": 0.97\n    },\n    {\n      \"id\": \"PROJECT_MANAGEMENT_AND_PRODUCTIVITY\",\n      \"name\": \"Project Management and Administrative Uses\",\n      \"description\": \"Potential uses of AI for project staffing, budgeting, labor forecasting, and other administrative tasks. Interviewee noted internal data could be leveraged to automate aspects of staffing and forecasting, and that some groups are underusing internal tools.\",\n      \"semantic_definition\": \"Statements about applying AI to administrative or project management tasks such as staffing forecasts, budget allocation, or workload management.\",\n      \"parent_id\": null,\n      \"level\": 0,\n      \"example_quotes\": [\n        \"We don’t use some of the internal budgeting and figuring out where ppl have labor allocated to do labor forecasting.\",\n        \"Thinking about how we already have a lot of data there and how we can pull it... to staff projects I’m bidding.\"\n      ],\n      \"discovery_confidence\": 0.88\n    },\n    {\n      \"id\": \"PROJECT_RESOURCE_FORECASTING\",\n      \"name\": \"Resource Allocation and Forecasting\",\n      \"description\": \"Use cases for predicting staffing needs, allocating labor across projects, and using existing administrative data to inform bidding and staffing decisions. Observes that PhD-level researchers may be less focused on management tasks.\",\n      \"semantic_definition\": \"Any instance suggesting AI-assisted forecasting or analysis of labor allocation, budgeting, or staffing for project planning.\",\n      \"parent_id\": \"PROJECT_MANAGEMENT_AND_PRODUCTIVITY\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"We don’t use some of the internal budgeting and figuring out where ppl have labor allocated to do labor forecasting.\",\n        \"Thinking about how we already have a lot of data there and how we can pull it... to staff projects I’m bidding.\"\n      ],\n      \"discovery_confidence\": 0.8\n    },\n    {\n      \"id\": \"PROJECT_ADMIN_AUTOMATION\",\n      \"name\": \"Administrative Task Automation\",\n      \"description\": \"AI-assisted automation for routine administrative tasks (e.g., summarization, tracking legislation, time summaries) as practiced in other professions and suggested for RAND. The interviewee’s sister uses AI to track legislation and summarize time use.\",\n      \"semantic_definition\": \"References to using AI to automate routine administrative functions such as tracking documents, summarizing activities, or monitoring legislative changes.\",\n      \"parent_id\": \"PROJECT_MANAGEMENT_AND_PRODUCTIVITY\",\n      \"level\": 1,\n      \"example_quotes\": [\n        \"I have a sister who is an attorney and she uses it in ways I would not think of. They track legislation and they are getting summaries or tracking how we spend their time.\",\n        \"My experience is that the PH.D. level ppl are less great about management so they may have not as much incite...\"\n      ],\n      \"discovery_confidence\": 0.75\n    }\n  ],\n  \"total_codes\": 34,\n  \"analysis_confidence\": 0.9\n}\n\nPHASE 2: PARTICIPANT PERSPECTIVE ANALYSIS  \n{\n  \"participants\": [\n    {\n      \"name\": \"Kandice Kapinos\",\n      \"role\": \"Director, Methods Center for Causal Inference\",\n      \"characteristics\": [\n        \"Senior researcher and center director\",\n        \"Pragmatic, early adopter of AI for productivity tasks\",\n        \"Causal inference methodologist (values RCT as gold standard)\",\n        \"Practical focus on data workflows, reproducibility, and proposal success\",\n        \"Cautious about ethics/IP and hallucination risks\",\n        \"Advocate for internal training and peer showcases\"\n      ],\n      \"perspective_summary\": \"Sees the Methods Center primarily as a convener and support hub for causal inference methods (seminars, journal clubs, seed funding) and emphasizes common quasi-experimental methods (DiD, synthetic control, IV, propensity scores) selected based on data. She actively uses LLMs for practical, time-saving tasks — debugging/refactoring code, proposal drafting and critique, literature-screening, simplifying technical text, and occasionally image generation — but emphasizes limits: AI is poor at deep, conceptual scientific reasoning, can hallucinate (fabricated citations), and raises IP concerns (more for prose/images than code). She reports growing but uneven adoption at RAND, notes policy-related hesitancy, and recommends more short, practical trainings and showcases.\",\n      \"codes_emphasized\": [\n        \"METHODS_CENTER\",\n        \"METHODS_CENTER_FUNCTIONS\",\n        \"METHODS_CENTER_HISTORY_AND_STRUCTURE\",\n        \"CAUSAL_METHODS\",\n        \"CAUSAL_COMMON_METHODS\",\n        \"CAUSAL_METHODS_SELECTION_AND_LIMITATIONS\",\n        \"AI_USAGE\",\n        \"AI_CODE_HELP\",\n        \"AI_CODE_REFACTORING\",\n        \"AI_PROPOSAL_SUPPORT\",\n        \"AI_LITERATURE_REVIEW\",\n        \"AI_COMMUNICATION_SIMPLIFICATION\",\n        \"AI_IMAGE_SUPPORT\",\n        \"AI_TOOLS\",\n        \"TOOL_RAND_CHAT\",\n        \"TOOL_CLAUDE\",\n        \"TOOL_SUBSCRIPTION_AI\",\n        \"DATA_WORKFLOWS\",\n        \"DATA_PULLING_AUTOMATION\",\n        \"DATA_CLEANING_AND_PREPARATION\",\n        \"REPRODUCIBILITY_AND_CODE_SHARING\",\n        \"BENEFITS_LIMITATIONS_OF_AI\",\n        \"AI_TIME_SAVINGS\",\n        \"AI_LIMITS_ON_CONCEPTUAL_WORK\",\n        \"AI_ERROR_AND_HALLUCINATION_RISK\",\n        \"ADOPTION_AND_TRAINING\",\n        \"ADOPTION_LEVEL\",\n        \"POLICY_AND_RESTRICTION_IMPACT\",\n        \"TRAINING_AND_SHOWCASING\",\n        \"ETHICS_AND_IP\",\n        \"IP_CONCERNS_CODE_VS_TEXT\",\n        \"CITATION_AND_HALLUCINATION_CONCERNS\",\n        \"PROJECT_MANAGEMENT_AND_PRODUCTIVITY\",\n        \"PROJECT_RESOURCE_FORECASTING\",\n        \"PROJECT_ADMIN_AUTOMATION\"\n      ]\n    }\n  ],\n  \"consensus_themes\": [\n    \"AI/LLMs provide measurable time savings on repetitive, tedious tasks (code debugging/refactoring, literature screening, executive summaries).\",\n    \"AI has important limitations for high-level conceptual work: designing credible causal analyses and making substantive scientific judgments remain human responsibilities.\",\n    \"Common causal inference methods in practice include difference-in-differences, synthetic control, instrumental variables, propensity scores, and interrupted time series; method choice is driven by available data.\",\n    \"Adoption of AI is uneven: growing interest and external uptake (conferences) but slower or cautious internal adoption at RAND.\",\n    \"There is a clear need for more training, peer showcases, and sharing of practical workflows to accelerate safe, effective use.\",\n    \"Significant concerns exist about hallucinations and citation accuracy, and ethical/IP risks—especially for generated prose and images (less concern for code reuse).\",\n    \"Data acquisition, cleaning, and reproducibility tasks are time-consuming and seen as promising targets for automation and AI assistance.\"\n  ],\n  \"divergent_viewpoints\": [\n    \"Acceptability of reuse: many are comfortable with AI-assisted code reuse, while there is stronger concern about AI producing prose or images that may infringe on others' IP.\",\n    \"Trust in specific tools: RAND Chat is perceived as useful for tedious tasks but less reliable (hallucinations) compared with other commercial/subscription tools like Claude, which some perceive as stronger for writing.\",\n    \"Organizational policy effects: some staff may be hesitant to use external AI tools because of institutional guidance or classified work constraints, whereas others actively adopt subscription tools despite policy ambiguity.\",\n    \"Scope of automation: disagreement exists about how far AI should be applied (safe gains in administrative/project management automation vs. reluctance to outsource conceptual scientific reasoning).\"\n  ],\n  \"perspective_mapping\": {\n    \"Kandice Kapinos\": [\n      \"METHODS_CENTER\",\n      \"METHODS_CENTER_FUNCTIONS\",\n      \"METHODS_CENTER_HISTORY_AND_STRUCTURE\",\n      \"CAUSAL_METHODS\",\n      \"CAUSAL_COMMON_METHODS\",\n      \"CAUSAL_METHODS_SELECTION_AND_LIMITATIONS\",\n      \"AI_USAGE\",\n      \"AI_CODE_HELP\",\n      \"AI_CODE_REFACTORING\",\n      \"AI_PROPOSAL_SUPPORT\",\n      \"AI_LITERATURE_REVIEW\",\n      \"AI_COMMUNICATION_SIMPLIFICATION\",\n      \"AI_IMAGE_SUPPORT\",\n      \"AI_TOOLS\",\n      \"TOOL_RAND_CHAT\",\n      \"TOOL_CLAUDE\",\n      \"TOOL_SUBSCRIPTION_AI\",\n      \"DATA_WORKFLOWS\",\n      \"DATA_PULLING_AUTOMATION\",\n      \"DATA_CLEANING_AND_PREPARATION\",\n      \"REPRODUCIBILITY_AND_CODE_SHARING\",\n      \"BENEFITS_LIMITATIONS_OF_AI\",\n      \"AI_TIME_SAVINGS\",\n      \"AI_LIMITS_ON_CONCEPTUAL_WORK\",\n      \"AI_ERROR_AND_HALLUCINATION_RISK\",\n      \"ADOPTION_AND_TRAINING\",\n      \"ADOPTION_LEVEL\",\n      \"POLICY_AND_RESTRICTION_IMPACT\",\n      \"TRAINING_AND_SHOWCASING\",\n      \"ETHICS_AND_IP\",\n      \"IP_CONCERNS_CODE_VS_TEXT\",\n      \"CITATION_AND_HALLUCINATION_CONCERNS\",\n      \"PROJECT_MANAGEMENT_AND_PRODUCTIVITY\",\n      \"PROJECT_RESOURCE_FORECASTING\",\n      \"PROJECT_ADMIN_AUTOMATION\"\n    ]\n  }\n}\n\nPHASE 3: ENTITY AND RELATIONSHIP MAPPING\n{\n  \"entities\": [\n    \"Methods Center for Causal Inference\",\n    \"Kandice Kapinos\",\n    \"RAND\",\n    \"RAND Chat\",\n    \"Claude\",\n    \"Subscription-based AI products\",\n    \"AI / LLMs\",\n    \"Otter\",\n    \"Causal inference methods\",\n    \"Randomized controlled trial (RCT)\",\n    \"Difference-in-differences (DiD)\",\n    \"Synthetic control\",\n    \"Instrumental variables (IV)\",\n    \"Propensity score matching\",\n    \"Interrupted time series\",\n    \"Data workflows\",\n    \"APIs\",\n    \"SQL\",\n    \"Data pulling / retrieval\",\n    \"Data cleaning and preparation\",\n    \"Code debugging and refactoring\",\n    \"Reproducibility and code annotation\",\n    \"Proposal writing and executive summaries\",\n    \"Literature review automation\",\n    \"DEI flagging / text sensitivity\",\n    \"Image / visual generation\",\n    \"Hallucination / fabricated citations\",\n    \"Intellectual property (IP) concerns\",\n    \"Organizational policy / guidance\",\n    \"Adoption and training\",\n    \"Project management and resource forecasting\",\n    \"Federal agency (client)\",\n    \"Librarian\"\n  ],\n  \"relationships\": [\n    {\n      \"entity_1\": \"Kandice Kapinos\",\n      \"entity_2\": \"Methods Center for Causal Inference\",\n      \"relationship_type\": \"leads\",\n      \"strength\": 0.9,\n      \"supporting_evidence\": [\n        \"Interview with Kandice Kapinos, Director Methods Center for Causal Inference\",\n        \"I view the Center as a convener of researchers who have expertise in causal inference techniques.\"\n      ]\n    },\n    {\n      \"entity_1\": \"Methods Center for Causal Inference\",\n      \"entity_2\": \"seminars / journal clubs / seed funding\",\n      \"relationship_type\": \"provides / hosts\",\n      \"strength\": 0.8,\n      \"supporting_evidence\": [\n        \"we host seminars and journal clubs to bring the methods to others and we are experimenting with a few things, using seed funding to help with preproposal work that is done.\",\n        \"The center has changed a bit but we host seminars and journal clubs...\"\n      ]\n    },\n    {\n      \"entity_1\": \"Methods Center for Causal Inference\",\n      \"entity_2\": \"causal inference methods\",\n      \"relationship_type\": \"promotes / convenes expertise in\",\n      \"strength\": 0.8,\n      \"supporting_evidence\": [\n        \"I view the Center as a convener of researchers who have expertise in causal inference techniques.\",\n        \"Tell me about the Methods Center on Causal Inference? ... I view the Center as a convener of researchers who have expertise in causal inference techniques.\"\n      ]\n    },\n    {\n      \"entity_1\": \"Randomized controlled trial (RCT)\",\n      \"entity_2\": \"causal inference methods\",\n      \"relationship_type\": \"considered_gold_standard_of\",\n      \"strength\": 0.95,\n      \"supporting_evidence\": [\n        \"The randomized control trial is our gold standard but they don’t happen that often, particularly in a policy evaluation setting\"\n      ]\n    },\n    {\n      \"entity_1\": \"Data availability\",\n      \"entity_2\": \"Method selection (causal inference)\",\n      \"relationship_type\": \"determines / constrains\",\n      \"strength\": 0.9,\n      \"supporting_evidence\": [\n        \"Depends on the data bc what do you have available to do an evaluation so that determines the hierarchy.\",\n        \"I would say that they are pretty broad and depends on the data bc what do you have available to do an evaluation so that determines the hierarchy.\"\n      ]\n    },\n    {\n      \"entity_1\": \"AI / LLMs\",\n      \"entity_2\": \"code debugging and refactoring\",\n      \"relationship_type\": \"assists_with\",\n      \"strength\": 0.9,\n      \"supporting_evidence\": [\n        \"I have used AI tools to help with my code.\",\n        \"I can take the code and put it in an LLM; can you fix this error or can you write this more concisely?\"\n      ]\n    },\n    {\n      \"entity_1\": \"AI / LLMs\",\n      \"entity_2\": \"proposal writing and executive summaries\",\n      \"relationship_type\": \"assists_with / drafts / summarizes\",\n      \"strength\": 0.85,\n      \"supporting_evidence\": [\n        \"I take the whole proposal and say write an executive summary; it is great at doing that; you can’t trust it but sometimes stuff that is off and misses nuance\",\n        \"I’ve also done things for proposal writing and taken my idea ... poke holes in this; What are the problems with this; how can I strengthen this?\"\n      ]\n    },\n    {\n      \"entity_1\": \"AI / LLMs\",\n      \"entity_2\": \"literature review automation\",\n      \"relationship_type\": \"automates / speeds_up\",\n      \"strength\": 0.9,\n      \"supporting_evidence\": [\n        \"we did the literature review and had it spit out in a spreadsheet a once sentence summary of the paper ... it was pretty good.\",\n        \"The client a federal agency wanted us to do this massive literature review in one month. ... it went through [3500 papers].\"\n      ]\n    },\n    {\n      \"entity_1\": \"AI / LLMs\",\n      \"entity_2\": \"hallucination / fabricated citations\",\n      \"relationship_type\": \"can_produce / prone_to\",\n      \"strength\": 0.9,\n      \"supporting_evidence\": [\n        \"The RAND CHAT one is not as good, a couple of times I would ask RAND CHAT ... and it would give me papers/citations that were not real.\",\n        \"Claude ... it gave me a bunch of links to the articles so I could check it unless you say give me the cite.\"\n      ]\n    },\n    {\n      \"entity_1\": \"RAND Chat\",\n      \"entity_2\": \"hallucination / fabricated citations\",\n      \"relationship_type\": \"exhibits / has_been_observed_to\",\n      \"strength\": 0.8,\n      \"supporting_evidence\": [\n        \"The RAND CHAT one is not as good, a couple of times I would ask RAND CHAT ... and it would give me papers/citations that were not real.\",\n        \"So I always check.\"\n      ]\n    },\n    {\n      \"entity_1\": \"Claude\",\n      \"entity_2\": \"writing and summarization\",\n      \"relationship_type\": \"effective_for\",\n      \"strength\": 0.8,\n      \"supporting_evidence\": [\n        \"My husband was using Claude and told me it is good at writing things.\",\n        \"Also, Claude, what do we know about this and it gave me a bunch of links to the articles so I could check it\"\n      ]\n    },\n    {\n      \"entity_1\": \"Organizational policy / guidance\",\n      \"entity_2\": \"Adoption and training\",\n      \"relationship_type\": \"influences / may_reduce\",\n      \"strength\": 0.75,\n      \"supporting_evidence\": [\n        \"I know RAND has its own specific rand chat and rand came out and said don’t use something, so part of me wonders if ppl are hesitant for that reason.\",\n        \"I guess if you are coding work that classified.\"\n      ]\n    },\n    {\n      \"entity_1\": \"Intellectual property (IP) concerns\",\n      \"entity_2\": \"image / visual generation and prose\",\n      \"relationship_type\": \"raises_concerns_about\",\n      \"strength\": 0.85,\n      \"supporting_evidence\": [\n        \"I don’t want to inadvertently take someone else’s intellectual property.\",\n        \"Saw a thing on john Oliver, ppl making images, based on what is in the public and making something new so it is kind of stealing.\"\n      ]\n    },\n    {\n      \"entity_1\": \"Code reuse\",\n      \"entity_2\": \"IP concerns\",\n      \"relationship_type\": \"perceived_as_less_risky_than_prose_images\",\n      \"strength\": 0.8,\n      \"supporting_evidence\": [\n        \"The code part I am not nervous at all, who cares if somebody takes my code and reuses it.\",\n        \"But if I were to take my proposal and say write this, is it going to take texts from others?\"\n      ]\n    },\n    {\n      \"entity_1\": \"Data pulling / retrieval and cleaning\",\n      \"entity_2\": \"time_consuming_tasks\",\n      \"relationship_type\": \"are\",\n      \"strength\": 0.95,\n      \"supporting_evidence\": [\n        \"But the time-consuming process of pulling data down, checking code.\",\n        \"We had to go and get it and clean and prepare it for use and check that there are not errors.\"\n      ]\n    },\n    {\n      \"entity_1\": \"AI / LLMs\",\n      \"entity_2\": \"data pulling / reproducibility / code annotation\",\n      \"relationship_type\": \"can_assist_with_automation_and_checks\",\n      \"strength\": 0.85,\n      \"supporting_evidence\": [\n        \"You can use the ai tools to check the code, annotate the code, replicability those are time consuming and for AI.\",\n        \"Some federal agencies are using the Api where you can tell it each time you run your code, go to this external website and pull data down fresh\"\n      ]\n    },\n    {\n      \"entity_1\": \"Project management and resource forecasting\",\n      \"entity_2\": \"AI / LLMs\",\n      \"relationship_type\": \"potential_use_case / can_be_automated\",\n      \"strength\": 0.7,\n      \"supporting_evidence\": [\n        \"We don’t use some of the internal budgeting and figuring out where ppl have labor allocated to do labor forecasting.\",\n        \"Thinking about how we already have a lot of data there and how we can pull it... to staff projects I’m bidding.\"\n      ]\n    },\n    {\n      \"entity_1\": \"Adoption and training\",\n      \"entity_2\": \"showcases / peer demonstrations\",\n      \"relationship_type\": \"enabled_by / increased_through\",\n      \"strength\": 0.8,\n      \"supporting_evidence\": [\n        \"There could be more along those lines, showcasing how ppl use it successfully.\",\n        \"A little bit but not a ton and someone super savvy and using it a lot could give a rundown of how they use it day to day.\"\n      ]\n    },\n    {\n      \"entity_1\": \"AI time savings\",\n      \"entity_2\": \"motivation_for_adoption\",\n      \"relationship_type\": \"drives\",\n      \"strength\": 0.85,\n      \"supporting_evidence\": [\n        \"It is speeding things up for ppl in a way that makes me feel I don’t want to be left behind\",\n        \"I’ve increased my use the past 6 months but I’ve been writing proposals non-stop.\"\n      ]\n    },\n    {\n      \"entity_1\": \"AI / LLMs\",\n      \"entity_2\": \"conceptual scientific reasoning / research design\",\n      \"relationship_type\": \"limited_in_replacing / cannot_replace\",\n      \"strength\": 0.95,\n      \"supporting_evidence\": [\n        \"It is not going to necessarily help you figure out what you need to do. The researcher has honed that overtime so not easily replicating it.\",\n        \"Thinking through the logic of the science and thinking is it credible, that is harder (for ai).\"\n      ]\n    },\n    {\n      \"entity_1\": \"Federal agency (client)\",\n      \"entity_2\": \"literature review automation\",\n      \"relationship_type\": \"drives_demand_for_fast_reviews\",\n      \"strength\": 0.75,\n      \"supporting_evidence\": [\n        \"The client a federal agency wanted us to do this massive literature review in one month.\",\n        \"So we ... we had a librarian gave us the initial list, it was originally 5,000 papers and removed duplicates down to 3500 that it went through.\"\n      ]\n    },\n    {\n      \"entity_1\": \"Librarian\",\n      \"entity_2\": \"literature review automation process\",\n      \"relationship_type\": \"provides_initial_input / supports\",\n      \"strength\": 0.7,\n      \"supporting_evidence\": [\n        \"we had a librarian gave us the initial list, it was originally 5,000 papers and removed duplicates down to 3500 that it went through.\"\n      ]\n    },\n    {\n      \"entity_1\": \"Subscription-based AI products\",\n      \"entity_2\": \"adoption_outside_RAND\",\n      \"relationship_type\": \"used_by_peers / observed_at_conferences\",\n      \"strength\": 0.7,\n      \"supporting_evidence\": [\n        \"I just went last week to the American society for health economists and heard lots of researchers that are using the subscription based ai products.\",\n        \"I think there is more use than just what I know.\"\n      ]\n    }\n  ],\n  \"cause_effect_chains\": [\n    \"Data availability -> Determines choice of causal method (DiD, IV, synthetic control, etc.) -> Affects credibility and validity of evaluation results\",\n    \"AI automates tedious tasks (code debugging, literature screening, executive summaries) -> Saves time and increases productivity -> Encourages individual adoption and perceived need to 'not be left behind'\",\n    \"Organizational policy warnings or unclear guidance -> Hesitancy to use external AI tools -> Slower internal adoption and uneven use across RAND\",\n    \"AI hallucinations / fabricated citations -> Necessitates human verification -> Lowers trust in certain AI outputs and increases vetting overhead\",\n    \"Lack of training / showcases -> Limited awareness of practical workflows -> Underutilization of AI for administrative/project management tasks\",\n    \"Demand from clients (e.g., federal agency) + librarian-provided lists -> Large-scale literature screening -> Use of LLMs to winnow papers quickly\"\n  ],\n  \"conceptual_connections\": [\n    \"Productivity vs. Trust tradeoff: AI provides time savings on repetitive tasks but introduces verification burden due to hallucinations and citation errors.\",\n    \"Method choice is data-driven, while AI supports operational aspects (coding, data prep, summarization) rather than high-level causal reasoning or study design.\",\n    \"Adoption is a function of perceived time savings, tool reliability (RAND Chat vs commercial tools), organizational policy, and availability of peer training/showcases.\",\n    \"Low-risk, high-reward domains (data retrieval, cleaning, reproducibility checks, administrative forecasting) are prime targets for initial AI integration within research organizations.\",\n    \"Ethical differentiation: code reuse is culturally and ethically tolerated more than reuse of prose or images, which raises stronger IP concerns.\",\n    \"External demand (clients, conferences) and internal champions (savvy users) together accelerate experimentation with AI tools and surface new use cases (e.g., DEI flagging, legislation tracking).\"\n  ]\n}\n\nPHASE 4: SYNTHESIS AND FINAL ANALYSIS\n{\n  \"executive_summary\": \"This synthesis integrates all analytic phases into a concise picture: the Methods Center for Causal Inference is positioned as a convener and practical support hub for causal methods; common causal techniques (RCT as gold standard, DiD, synthetic control, IV, propensity scores, interrupted time series) are selected primarily based on data availability; AI/LLMs are actively used by the interviewee for productivity tasks (code debugging/refactoring, proposal drafting/editing, literature-screening, text simplification, and occasional image generation) and deliver measurable time savings but carry significant limits (hallucinations, citation errors, limited conceptual/scientific reasoning) and ethical/IP concerns (stronger for prose/images than code). Adoption at RAND is growing but uneven and influenced by organizational policy, tool reliability (internal RAND Chat vs commercial tools like Claude), and lack of accessible peer-led training. High-value near-term opportunities include formalizing verification workflows, piloting AI-assisted data/workflow automation (APIs, reproducibility checks), and delivering short, practical trainings and showcases to accelerate safe adoption. Recommended actions balance enabling productivity gains while preserving human oversight for scientific judgment and protecting IP/trust.\",\n  \"key_findings\": [\n    \"Methods Center role and activities: The Center functions primarily as a convener that hosts seminars, journal clubs, and provides seed funding to incubate proposals, and its mission has evolved with organizational moves (e.g., from Pardee to GER). Evidence: direct interview statements describing seminars/journal clubs and seed-funding experiments. Estimated frequency in dataset: 100% (present across the full interview); analysis confidence: high (0.95).\",\n    \"Causal methods practice: Researchers rely on a core set of quasi-experimental methods when RCTs are infeasible — difference-in-differences, synthetic control, instrumental variables, propensity scores, and interrupted time series — with method choice determined by available data. Evidence: enumerated list of methods and repeated emphasis that selection 'depends on the data.' Estimated frequency: 100% (all method discussion segments); confidence: high (0.98).\",\n    \"AI used for code assistance: LLMs are regularly used to debug, translate, refactor, and annotate code, helping to reduce time spent resolving package-specific or idiosyncratic errors. Evidence: multiple examples of converting R to Stata, fixing errors, making code concise. Estimated usage prevalence within interview: high (reported personally and by peers) ~70% relative prominence among AI use cases; confidence: high (0.97).\",\n    \"AI used for proposal work: LLMs are used intensively for drafting, summarizing (executive summaries), critiquing proposals, and 'poking holes' in designs — producing substantial productivity gains but sometimes missing nuance. Evidence: repeated descriptions of taking entire proposals to ask for summaries and critique. Estimated prominence: very high (one of the interviewee's primary uses) ~80%; confidence: high (0.96).\",\n    \"AI for literature-review automation: LLM-assisted scripts have been used to screen thousands of papers and produce one-sentence summaries/metadata to winnow large review workloads, enabling deadlines to be met. Evidence: a project using RAND Chat to process ~3,500 papers for a federal client. Estimated prevalence across use-cases: medium-high ~50%; confidence: high (0.94).\",\n    \"Time-savings vs conceptual limits: AI provides clear time savings on repetitive tasks (summaries, code fixes, screening) but is limited at higher-level conceptual scientific reasoning, research design choices, and credibility judgments. Evidence: interview repeatedly contrasts productivity gains with inability of AI to 'think through the logic of the science.' Estimated pattern prevalence: universal within AI discussion ~100%; confidence: high (0.97).\",\n    \"Hallucination and citation risk: LLMs (including RAND Chat) have produced fabricated or inaccurate citations and links, requiring human verification and reducing trust in some outputs. Evidence: specific instances of RAND Chat returning non-real papers and the interviewee's practice of always checking citations. Estimated practical impact: high (significant verification overhead) ~70%; confidence: high (0.96).\",\n    \"Ethics/IP concerns: Interviewee is comfortable with code reuse but expresses stronger concerns about AI-produced prose and images potentially infringing on others' intellectual property. Evidence: explicit distinction in interview about code being 'not an issue' versus worries about prose/images. Estimated concern prevalence: high among content types ~75% for prose/images, low for code ~15%; confidence: high (0.96).\",\n    \"Adoption is uneven and policy-sensitive: Uptake at RAND is growing but uneven; adoption is shaped by organizational guidance (e.g., RAND Chat restrictions), perceived tool reliability, and limited peer demonstrations/training. Evidence: interviewee notes fewer users internally, conference observations of subscription tool uptake, and RAND guidance potentially deterring use. Estimated adoption pattern: mixed — early adopters concentrated in certain tasks ~40% internal active use; confidence: medium-high (0.88–0.95 depending on subtheme).\",\n    \"Data workflows are time-consuming and promising for automation: Pulling, cleaning, and validating data (including API-based refreshes and managing large public datasets) are labor-intensive and represent low-risk, high-reward targets for automation and reproducibility tooling. Evidence: repeated emphasis on time-consuming data pulls, cleaning, and use of APIs to auto-refresh data. Estimated relevance as target for AI: high ~85%; confidence: high (0.96).\"\n  ],\n  \"cross_cutting_patterns\": [\n    \"Productivity vs. Trust tradeoff: AI delivers clear time savings on repetitive tasks but introduces a verification burden (hallucinations, citation errors) that reduces trust in unsupervised outputs.\",\n    \"Human-in-the-loop necessity for science: AI supports operational tasks (code fixes, data pulls, summarization) but cannot replace human conceptual reasoning for study design and credibility assessment.\",\n    \"Data-driven method selection: Choice of causal method is consistently framed as constrained by the data available, making robust data workflows and automation critical enablers for methodological rigor.\",\n    \"Ethical differentiation by artifact type: Cultural and ethical tolerance differs by artifact — code reuse is broadly acceptable while generated prose and images trigger stronger IP/attribution concerns.\",\n    \"Adoption determined by policy, reliability, and peer learning: Organizational guidance and perceived tool reliability (internal vs. commercial LLMs) plus availability of short, practical peer showcases determine uptake speed and breadth.\",\n    \"Low-risk/high-reward integration areas: Administrative and data-management tasks (APIs, reproducibility checks, literature screening, project staffing forecasts) are prime initial targets for safe AI adoption with measurable ROI.\"\n  ],\n  \"actionable_recommendations\": [\n    {\n      \"title\": \"Launch short, practical AI showcases and 'how-I-use-it' sessions\",\n      \"description\": \"Organize a recurring series of 30–60 minute demonstrations led by experienced internal users (and invited external users where helpful) showcasing day-to-day workflows: code debugging with LLMs, proposal executive-summary drafting, literature-screening pipelines, and DEI-flagging examples. Emphasize concrete prompts, input/output vetting steps, and time-savings realized. Make recordings, prompt templates, and example notebooks available on an internal repository.\",\n      \"priority\": \"high\",\n      \"supporting_themes\": [\n        \"ADOPTION_AND_TRAINING\",\n        \"TRAINING_AND_SHOWCASING\",\n        \"AI_CODE_HELP\",\n        \"AI_PROPOSAL_SUPPORT\",\n        \"AI_LITERATURE_REVIEW\"\n      ]\n    },\n    {\n      \"title\": \"Develop formal AI guidance and permissible-use checklist (tool- and data-class aware)\",\n      \"description\": \"Create clear, role-specific guidance that reconciles organizational policy with practical use: (a) what can be used on RAND Chat vs external subscription tools, (b) handling classified or sensitive data, (c) verification steps required for citations and generated prose/images, and (d) recommended default settings for logging and auditing AI interactions. Tie guidance to approval pathways and a frequently-updated FAQ informed by ongoing showcases.\",\n      \"priority\": \"high\",\n      \"supporting_themes\": [\n        \"POLICY_AND_RESTRICTION_IMPACT\",\n        \"TOOL_RAND_CHAT\",\n        \"TOOL_SUBSCRIPTION_AI\",\n        \"CITATION_AND_HALLUCINATION_CONCERNS\",\n        \"ETHICS_AND_IP\"\n      ]\n    },\n    {\n      \"title\": \"Create and mandate a lightweight verification workflow for AI outputs\",\n      \"description\": \"Require a standard, minimal human-in-the-loop verification checklist whenever AI is used for literature synthesis, citation generation, or substantive claims: (1) confirm citations exist and match claims, (2) spot-check a random sample of AI-generated summaries against original text, (3) log prompts and outputs for reproducibility, and (4) annotate any AI-derived text in deliverables. Provide tools and templates (e.g., spreadsheet checks, automated DOI lookups) to reduce verification overhead.\",\n      \"priority\": \"high\",\n      \"supporting_themes\": [\n        \"AI_ERROR_AND_HALLUCINATION_RISK\",\n        \"CITATION_AND_HALLUCINATION_CONCERNS\",\n        \"REPRODUCIBILITY_AND_CODE_SHARING\",\n        \"AI_LITERATURE_REVIEW\"\n      ]\n    },\n    {\n      \"title\": \"Pilot automation of data-pulling and reproducibility checks\",\n      \"description\": \"Design 2–3 pilot projects that automate API-based data retrieval, standardized cleaning pipelines, and reproducibility checks (e.g., auto-run notebooks that pull data, validate shapes and summary statistics, and annotate code). Target projects with public datasets or repetitive pulls to maximize ROI. Measure time saved and error reductions to build the business case for broader roll-out.\",\n      \"priority\": \"medium\",\n      \"supporting_themes\": [\n        \"DATA_PULLING_AUTOMATION\",\n        \"DATA_CLEANING_AND_PREPARATION\",\n        \"REPRODUCIBILITY_AND_CODE_SHARING\",\n        \"AI_TIME_SAVINGS\"\n      ]\n    },\n    {\n      \"title\": \"Establish IP/ethics guidance distinguishing code reuse from prose/image concerns\",\n      \"description\": \"Develop a short internal policy clarifying norms and expectations: code may be shared and reused with attribution encouraged but prose/images generated by LLMs must be treated with caution (check for uncredited source material, avoid direct reuse of others' copyrighted prose/images). Provide legal/IP FAQs and sample attribution language for AI-assisted outputs.\",\n      \"priority\": \"medium\",\n      \"supporting_themes\": [\n        \"ETHICS_AND_IP\",\n        \"IP_CONCERNS_CODE_VS_TEXT\",\n        \"AI_IMAGE_SUPPORT\"\n      ]\n    },\n    {\n      \"title\": \"Curate and recommend a small set of vetted AI tools and configurations\",\n      \"description\": \"Based on internal pilots and external evidence, produce a short list of recommended tools for specific tasks (e.g., RAND Chat for internal code tasks with logging; subscription tool X for writing/summarization with citation-checking features). Document best-practice prompt templates and known failure modes per tool to guide users toward reliable outcomes.\",\n      \"priority\": \"medium\",\n      \"supporting_themes\": [\n        \"AI_TOOLS\",\n        \"TOOL_RAND_CHAT\",\n        \"TOOL_CLAUDE\",\n        \"TOOL_SUBSCRIPTION_AI\",\n        \"ADOPTION_LEVEL\"\n      ]\n    },\n    {\n      \"title\": \"Explore AI for administrative/project-management automation (pilot labor forecasting)\",\n      \"description\": \"Pilot an AI-assisted administrative application: use existing internal staffing and budgeting data to prototype labor-forecasting dashboards or automated time-summarization tools. Engage project managers and a small group of PhD researchers to validate forecasts and refine features before scaling.\",\n      \"priority\": \"low\",\n      \"supporting_themes\": [\n        \"PROJECT_RESOURCE_FORECASTING\",\n        \"PROJECT_ADMIN_AUTOMATION\",\n        \"PROJECT_MANAGEMENT_AND_PRODUCTIVITY\"\n      ]\n    }\n  ],\n  \"confidence_assessment\": {\n    \"Methods Center Role\": {\n      \"level\": \"high\",\n      \"score\": 0.95,\n      \"evidence\": \"Phase 1 code 'METHODS_CENTER' discovery_confidence 0.95 and multiple explicit interview statements about convening, seminars, journal clubs and seed funding.\"\n    },\n    \"Causal Methods (practice & selection)\": {\n      \"level\": \"high\",\n      \"score\": 0.98,\n      \"evidence\": \"Phase 1 'CAUSAL_METHODS' discovery_confidence 0.98 and explicit enumeration of RCT, DiD, synthetic control, IV, propensity scores; plus statements that method choice 'depends on the data'.\"\n    },\n    \"AI Usage (general)\": {\n      \"level\": \"high\",\n      \"score\": 0.98,\n      \"evidence\": \"Phase 1 'AI_USAGE' discovery_confidence 0.98 and multiple uses described (code, proposals, literature reviews, explainability, images).\"\n    },\n    \"AI code help (debugging/refactor/translate)\": {\n      \"level\": \"high\",\n      \"score\": 0.97,\n      \"evidence\": \"Phase 1 'AI_CODE_HELP' and 'AI_CODE_REFACTORING' discovery_confidences 0.97/0.92; interview examples converting R to Stata and fixing errors.\"\n    },\n    \"AI proposal support\": {\n      \"level\": \"high\",\n      \"score\": 0.96,\n      \"evidence\": \"Phase 1 'AI_PROPOSAL_SUPPORT' discovery_confidence 0.96; multiple interview examples of drafting executive summaries and critique.\"\n    },\n    \"AI literature review automation\": {\n      \"level\": \"high\",\n      \"score\": 0.94,\n      \"evidence\": \"Phase 1 'AI_LITERATURE_REVIEW' discovery_confidence 0.94; concrete project processing ~3,500 papers described.\"\n    },\n    \"AI hallucination & citation risks\": {\n      \"level\": \"high\",\n      \"score\": 0.96,\n      \"evidence\": \"Phase 1 'AI_ERROR_AND_HALLUCINATION_RISK' discovery_confidence 0.96; specific incidents of RAND Chat fabricating citations noted.\"\n    },\n    \"Benefits vs limits (productivity vs conceptual limits)\": {\n      \"level\": \"high\",\n      \"score\": 0.97,\n      \"evidence\": \"Phase 1 'BENEFITS_LIMITATIONS_OF_AI' and 'AI_LIMITS_ON_CONCEPTUAL_WORK' discovery_confidences 0.97 each; interview repeatedly contrasts time savings with inability to replace scientific reasoning.\"\n    },\n    \"Adoption & training needs\": {\n      \"level\": \"high\",\n      \"score\": 0.95,\n      \"evidence\": \"Phase 1 'ADOPTION_AND_TRAINING' discovery_confidence 0.95 and interview calls for showcases and short trainings.\"\n    },\n    \"Policy & restriction impact on adoption\": {\n      \"level\": \"medium\",\n      \"score\": 0.9,\n      \"evidence\": \"Phase 1 'POLICY_AND_RESTRICTION_IMPACT' discovery_confidence 0.9; interview suggests RAND guidance and classification concerns may deter some users, but magnitude of effect across RAND is uncertain.\"\n    },\n    \"Ethics / IP concerns\": {\n      \"level\": \"high\",\n      \"score\": 0.96,\n      \"evidence\": \"Phase 1 'ETHICS_AND_IP' discovery_confidence 0.96 with explicit interview distinctions between code reuse (acceptable) and prose/image reuse (concerning).\"\n    },\n    \"Data workflows and automation potential\": {\n      \"level\": \"high\",\n      \"score\": 0.96,\n      \"evidence\": \"Phase 1 'DATA_WORKFLOWS', 'DATA_PULLING_AUTOMATION', 'DATA_CLEANING_AND_PREPARATION' discovery_confidences 0.96/0.9/0.96; multiple descriptions of time-consuming data pulls and use of APIs.\"\n    },\n    \"Project management & administrative use cases\": {\n      \"level\": \"medium\",\n      \"score\": 0.88,\n      \"evidence\": \"Phase 1 'PROJECT_MANAGEMENT_AND_PRODUCTIVITY' and related codes discovery_confidence 0.88; interview mentions potential but fewer concrete examples within RAND.\"\n    },\n    \"Tool-specific reliability (RAND Chat vs Claude vs subscription tools)\": {\n      \"level\": \"medium-high\",\n      \"score\": 0.9,\n      \"evidence\": \"Phase 1 'TOOL_RAND_CHAT' and 'TOOL_CLAUDE' discovery_confidences 0.9; interview provides specific comparative anecdotes (RAND Chat hallucinations vs Claude better at writing), but broader tool landscape evolves quickly.\"\n    }\n  }\n}\n\n=== END OF ANALYSIS ===",
    "key_relationships": [
      {
        "entities": "Kandice Kapinos -> Methods Center for Causal Inference",
        "strength": 0.9,
        "type": "leads"
      },
      {
        "entities": "Methods Center for Causal Inference -> seminars / journal clubs / seed funding",
        "strength": 0.8,
        "type": "provides / hosts"
      },
      {
        "entities": "Methods Center for Causal Inference -> causal inference methods",
        "strength": 0.8,
        "type": "promotes / convenes expertise in"
      },
      {
        "entities": "Randomized controlled trial (RCT) -> causal inference methods",
        "strength": 0.95,
        "type": "considered_gold_standard_of"
      },
      {
        "entities": "Data availability -> Method selection (causal inference)",
        "strength": 0.9,
        "type": "determines / constrains"
      },
      {
        "entities": "AI / LLMs -> code debugging and refactoring",
        "strength": 0.9,
        "type": "assists_with"
      },
      {
        "entities": "AI / LLMs -> proposal writing and executive summaries",
        "strength": 0.85,
        "type": "assists_with / drafts / summarizes"
      },
      {
        "entities": "AI / LLMs -> literature review automation",
        "strength": 0.9,
        "type": "automates / speeds_up"
      },
      {
        "entities": "AI / LLMs -> hallucination / fabricated citations",
        "strength": 0.9,
        "type": "can_produce / prone_to"
      },
      {
        "entities": "RAND Chat -> hallucination / fabricated citations",
        "strength": 0.8,
        "type": "exhibits / has_been_observed_to"
      },
      {
        "entities": "Claude -> writing and summarization",
        "strength": 0.8,
        "type": "effective_for"
      },
      {
        "entities": "Organizational policy / guidance -> Adoption and training",
        "strength": 0.75,
        "type": "influences / may_reduce"
      },
      {
        "entities": "Intellectual property (IP) concerns -> image / visual generation and prose",
        "strength": 0.85,
        "type": "raises_concerns_about"
      },
      {
        "entities": "Code reuse -> IP concerns",
        "strength": 0.8,
        "type": "perceived_as_less_risky_than_prose_images"
      },
      {
        "entities": "Data pulling / retrieval and cleaning -> time_consuming_tasks",
        "strength": 0.95,
        "type": "are"
      },
      {
        "entities": "AI / LLMs -> data pulling / reproducibility / code annotation",
        "strength": 0.85,
        "type": "can_assist_with_automation_and_checks"
      },
      {
        "entities": "Project management and resource forecasting -> AI / LLMs",
        "strength": 0.7,
        "type": "potential_use_case / can_be_automated"
      },
      {
        "entities": "Adoption and training -> showcases / peer demonstrations",
        "strength": 0.8,
        "type": "enabled_by / increased_through"
      },
      {
        "entities": "AI time savings -> motivation_for_adoption",
        "strength": 0.85,
        "type": "drives"
      },
      {
        "entities": "AI / LLMs -> conceptual scientific reasoning / research design",
        "strength": 0.95,
        "type": "limited_in_replacing / cannot_replace"
      },
      {
        "entities": "Federal agency (client) -> literature review automation",
        "strength": 0.75,
        "type": "drives_demand_for_fast_reviews"
      },
      {
        "entities": "Librarian -> literature review automation process",
        "strength": 0.7,
        "type": "provides_initial_input / supports"
      },
      {
        "entities": "Subscription-based AI products -> adoption_outside_RAND",
        "strength": 0.7,
        "type": "used_by_peers / observed_at_conferences"
      }
    ],
    "key_themes": [
      "Methods Center role and activities: The Center functions primarily as a convener that hosts seminars, journal clubs, and provides seed funding to incubate proposals, and its mission has evolved with organizational moves (e.g., from Pardee to GER). Evidence: direct interview statements describing seminars/journal clubs and seed-funding experiments. Estimated frequency in dataset: 100% (present across the full interview); analysis confidence: high (0.95).",
      "Causal methods practice: Researchers rely on a core set of quasi-experimental methods when RCTs are infeasible — difference-in-differences, synthetic control, instrumental variables, propensity scores, and interrupted time series — with method choice determined by available data. Evidence: enumerated list of methods and repeated emphasis that selection 'depends on the data.' Estimated frequency: 100% (all method discussion segments); confidence: high (0.98).",
      "AI used for code assistance: LLMs are regularly used to debug, translate, refactor, and annotate code, helping to reduce time spent resolving package-specific or idiosyncratic errors. Evidence: multiple examples of converting R to Stata, fixing errors, making code concise. Estimated usage prevalence within interview: high (reported personally and by peers) ~70% relative prominence among AI use cases; confidence: high (0.97).",
      "AI used for proposal work: LLMs are used intensively for drafting, summarizing (executive summaries), critiquing proposals, and 'poking holes' in designs — producing substantial productivity gains but sometimes missing nuance. Evidence: repeated descriptions of taking entire proposals to ask for summaries and critique. Estimated prominence: very high (one of the interviewee's primary uses) ~80%; confidence: high (0.96).",
      "AI for literature-review automation: LLM-assisted scripts have been used to screen thousands of papers and produce one-sentence summaries/metadata to winnow large review workloads, enabling deadlines to be met. Evidence: a project using RAND Chat to process ~3,500 papers for a federal client. Estimated prevalence across use-cases: medium-high ~50%; confidence: high (0.94).",
      "Time-savings vs conceptual limits: AI provides clear time savings on repetitive tasks (summaries, code fixes, screening) but is limited at higher-level conceptual scientific reasoning, research design choices, and credibility judgments. Evidence: interview repeatedly contrasts productivity gains with inability of AI to 'think through the logic of the science.' Estimated pattern prevalence: universal within AI discussion ~100%; confidence: high (0.97).",
      "Hallucination and citation risk: LLMs (including RAND Chat) have produced fabricated or inaccurate citations and links, requiring human verification and reducing trust in some outputs. Evidence: specific instances of RAND Chat returning non-real papers and the interviewee's practice of always checking citations. Estimated practical impact: high (significant verification overhead) ~70%; confidence: high (0.96).",
      "Ethics/IP concerns: Interviewee is comfortable with code reuse but expresses stronger concerns about AI-produced prose and images potentially infringing on others' intellectual property. Evidence: explicit distinction in interview about code being 'not an issue' versus worries about prose/images. Estimated concern prevalence: high among content types ~75% for prose/images, low for code ~15%; confidence: high (0.96).",
      "Adoption is uneven and policy-sensitive: Uptake at RAND is growing but uneven; adoption is shaped by organizational guidance (e.g., RAND Chat restrictions), perceived tool reliability, and limited peer demonstrations/training. Evidence: interviewee notes fewer users internally, conference observations of subscription tool uptake, and RAND guidance potentially deterring use. Estimated adoption pattern: mixed — early adopters concentrated in certain tasks ~40% internal active use; confidence: medium-high (0.88–0.95 depending on subtheme).",
      "Data workflows are time-consuming and promising for automation: Pulling, cleaning, and validating data (including API-based refreshes and managing large public datasets) are labor-intensive and represent low-risk, high-reward targets for automation and reproducibility tooling. Evidence: repeated emphasis on time-consuming data pulls, cleaning, and use of APIs to auto-refresh data. Estimated relevance as target for AI: high ~85%; confidence: high (0.96)."
    ],
    "model_used": "gpt-5-mini",
    "processing_time_seconds": 245.98,
    "recommendations": [
      {
        "description": "Organize a recurring series of 30–60 minute demonstrations led by experienced internal users (and invited external users where helpful) showcasing day-to-day workflows: code debugging with LLMs, proposal executive-summary drafting, literature-screening pipelines, and DEI-flagging examples. Emphasize concrete prompts, input/output vetting steps, and time-savings realized. Make recordings, prompt templates, and example notebooks available on an internal repository.",
        "priority": "high",
        "title": "Launch short, practical AI showcases and 'how-I-use-it' sessions"
      },
      {
        "description": "Create clear, role-specific guidance that reconciles organizational policy with practical use: (a) what can be used on RAND Chat vs external subscription tools, (b) handling classified or sensitive data, (c) verification steps required for citations and generated prose/images, and (d) recommended default settings for logging and auditing AI interactions. Tie guidance to approval pathways and a frequently-updated FAQ informed by ongoing showcases.",
        "priority": "high",
        "title": "Develop formal AI guidance and permissible-use checklist (tool- and data-class aware)"
      },
      {
        "description": "Require a standard, minimal human-in-the-loop verification checklist whenever AI is used for literature synthesis, citation generation, or substantive claims: (1) confirm citations exist and match claims, (2) spot-check a random sample of AI-generated summaries against original text, (3) log prompts and outputs for reproducibility, and (4) annotate any AI-derived text in deliverables. Provide tools and templates (e.g., spreadsheet checks, automated DOI lookups) to reduce verification overhead.",
        "priority": "high",
        "title": "Create and mandate a lightweight verification workflow for AI outputs"
      },
      {
        "description": "Design 2–3 pilot projects that automate API-based data retrieval, standardized cleaning pipelines, and reproducibility checks (e.g., auto-run notebooks that pull data, validate shapes and summary statistics, and annotate code). Target projects with public datasets or repetitive pulls to maximize ROI. Measure time saved and error reductions to build the business case for broader roll-out.",
        "priority": "medium",
        "title": "Pilot automation of data-pulling and reproducibility checks"
      },
      {
        "description": "Develop a short internal policy clarifying norms and expectations: code may be shared and reused with attribution encouraged but prose/images generated by LLMs must be treated with caution (check for uncredited source material, avoid direct reuse of others' copyrighted prose/images). Provide legal/IP FAQs and sample attribution language for AI-assisted outputs.",
        "priority": "medium",
        "title": "Establish IP/ethics guidance distinguishing code reuse from prose/image concerns"
      },
      {
        "description": "Based on internal pilots and external evidence, produce a short list of recommended tools for specific tasks (e.g., RAND Chat for internal code tasks with logging; subscription tool X for writing/summarization with citation-checking features). Document best-practice prompt templates and known failure modes per tool to guide users toward reliable outcomes.",
        "priority": "medium",
        "title": "Curate and recommend a small set of vetted AI tools and configurations"
      },
      {
        "description": "Pilot an AI-assisted administrative application: use existing internal staffing and budgeting data to prototype labor-forecasting dashboards or automated time-summarization tools. Engage project managers and a small group of PhD researchers to validate forecasts and refine features before scaling.",
        "priority": "low",
        "title": "Explore AI for administrative/project-management automation (pilot labor forecasting)"
      }
    ],
    "speakers_identified": [
      {
        "name": "Kandice Kapinos",
        "perspective": "Sees the Methods Center primarily as a convener and support hub for causal inference methods (seminars, journal clubs, seed funding) and emphasizes common quasi-experimental methods (DiD, synthetic control, IV, propensity scores) selected based on data. She actively uses LLMs for practical, time-saving tasks — debugging/refactoring code, proposal drafting and critique, literature-screening, simplifying technical text, and occasionally image generation — but emphasizes limits: AI is poor at deep, conceptual scientific reasoning, can hallucinate (fabricated citations), and raises IP concerns (more for prose/images than code). She reports growing but uneven adoption at RAND, notes policy-related hesitancy, and recommends more short, practical trainings and showcases.",
        "role": "Director, Methods Center for Causal Inference"
      }
    ],
    "total_interviews": 1
  },
  "started_at": "2026-02-10T18:44:01.462555",
  "status": "completed"
}